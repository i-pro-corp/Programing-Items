<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="kinoshita hidetosi (木下英俊)">
  <meta name="description" content="Introducing programming for i-PRO cameras.">
  <meta name="keywords" content="i-PRO">
  
  <!-- キャッシュ無効化 -->
  <meta http-equiv="Cache-Control" content="no-cache">
	
  <!-- タイトル -->
  <title>MJPEGで画像を取得する | i-PRO - Programming Items</title>
	
  <!-- ファビコン -->
  <link rel="shortcut icon" href="../../favicon.ico">

  <!-- CSS -->
  <link href="https://unpkg.com/ress/dist/ress.min.css" rel="stylesheet">
	<link rel="stylesheet" href="../../design.css" type="text/css">
  
	<!-- Start for 'google-code-prettify' -->
	<link href="../../prettify/styles/desert.css" rel="stylesheet" type="text/css">
	<script src="../../prettify/prettify.js" type="text/javascript"></script>
	<!-- End for 'google-code-prettify' -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5DFRG3H0KB"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5DFRG3H0KB');
  </script>  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  
  <style type="text/css">
    .auto-style2 {
      background-color: #505000;
    }
    .super {
      vertical-align: super;
    }
    .auto-style3 {
      text-decoration: underline;
    }
  </style>

</head>

<body onload="prettyPrint();">

<h1>MJPEG で画像を取得する (Python)</h1>

<p> &nbsp;</p>
    <div class="status_information">
      <div>
      </div>
      <div>
        <p>本ページは i-PRO株式会社 の有志メンバーにより記載されたものです。<br>本ページの情報は <a href="#ライセンス">ライセンス</a> に記載の条件で提供されます。</p>
      </div>
    </div>
<p> &nbsp;</p>

<div class="mokuji">
  <nav>
    <h2>目次</h2>
    <p><a href="#1._MJPEG 表記仕様">1. MJPEG 表記仕様</a></p>
    <p><a href="#2. i-PRO カメラと MJPEG 接続して映像を表示してみる">2. i-PRO カメラと MJPEG 接続して映像を表示してみる</a></p>
    <p>&nbsp; <a href="#2-1._方法1">2-1. 方法1</a></p>
    <p>&nbsp; <a href="#2-2._方法2">2-2. 方法2</a></p>
    <p><a href="#3.プログラムを改善する">3. プログラムを改善する</a></p>
    <p><a href="#4. OpenCV で顔検知を加えてみる">4. OpenCV で顔検知を加えてみる</a></p>
    <p>&nbsp; <a href="#4-1._まずは単純にやってみる">4-1. まずは単純にやってみる</a></p>
    <p>&nbsp; <a href="#4-2._顔検知部分を別プロセスの処理にしてみる">4-2. 顔検知部分を別プロセスの処理にしてみる</a></p>
    <p><a href="#5._連番の_JPEG_ファイルで保存する">5. 連番の JPEG ファイルで保存する</a></p>
    <p><a href="#6._映像切断時の再接続処理を追加">6.映像切断時の再接続処理を追加</a></p>
    <p><a href="#7._GUIで映像表示してみる（tkinter）">7.GUIで映像表示してみる（tkinter）</a></p>
    <br>
    <p><a href="#ソースコード所在">ソースコード所在</a></p>
    <p><a href="#ライセンス">ライセンス</a></p>
    <p><a href="#参考">参考</a></p>
  </nav>
</div>

<p> &nbsp;</p>
<p>&nbsp;</p>

<p>本ページでは、<strong>i-PRO</strong> カメラとPCを <strong>MJPEG</strong> により接続してPC画面へ表示するプログラムを Python 
で作成する例を紹介します。とても短いプログラムで i-PRO カメラの映像を見ることができます。動作確認は i-PRO mini (WV-S7130)、モジュールカメラ（AIスターターキット）を使って行いましたが、ほとんどの i-PRO 
カメラでそのまま利用できるはずです。ぜひお試しください。</p>
<p>&nbsp;</p>
  
<video controls muted autoplay="y" loop="y" width="800">
  <source src="connect_with_mjpeg/mjpeg_first_30fps.mp4" type="video/mp4">
  動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。
</video>
<p>[動画] MJPEG でカメラと接続して映像表示した様子</p>

<p> &nbsp;</p>
<hr>
<p>&nbsp;</p>

<section>
  <p class="auto-style3"> <strong>"i-PRO mini" 紹介： </strong> </p>
  <ul>
    <li><a href="https://cwc.i-pro.com/pages/i-pro-mini-lp" target="_blank">
      i-PRO mini</a></li>
    <li><a href="https://cwc.i-pro.com/collections/camera/products/wv-s7130ux" target="_blank">
      i-PRO mini 有線LANモデル WV-S7130UX</a></li>
    <li>  <a href="https://cwc.i-pro.com/collections/camera/products/wv-s7130wux" target="_blank">
      i-PRO mini 無線LANモデル WV-S7130WUX</a></li>
    <li><a href="https://japancs.i-pro.com/space/DLJP/724085590/WV-S7130UX　i-PRO+mini+有線LANモデル" target="_blank">
      WV-S7130UX　i-PRO mini 有線LANモデル - ダウンロード - i-PRO サポートポータル</a></li>
    <li><a href="https://japancs.i-pro.com/space/DLJP/724086255/WV-S7130WUX　i-PRO+mini+無線LANモデル" target="_blank">
      WV-S7130WUX　i-PRO mini 無線LANモデル - ダウンロード - i-PRO サポートポータル</a></li>
  </ul>
  <p><a href="images/i-PRO_mini.jpg" target="_blank">
    <img alt="i-PRO mini 画像" src="images/i-PRO_mini.jpg" class="border_with_drop-shadow" width="348"></a></p>
  <p>&nbsp;</p>
  <p class="auto-style3"><strong>"モジュールカメラ" 紹介：</strong></p>
  <ul>
    <li><a href="https://moduca.i-pro.com" target="_blank">
      モジュールカメラ｜ポータルサイト (i-pro.com)</a></li>
    <li><a href="https://moduca.i-pro.com/space/MCT/768743132/各種マニュアル" target="_blank">
      各種マニュアル - Module Camera Technical Information - モジュールカメラ｜ポータルサイト (i-pro.com)</a></li>
  </ul>
  <p>
    <a href="images/ai_starter_kit_1.png" target="_blank">
      <img alt="AI スターターキット 画像(1)" class="border_with_drop-shadow" src="images/ai_starter_kit_1.png" width="404"></a>
    <a href="images/ai_starter_kit_2.png" target="_blank">
      <img alt="AI スターターキット 画像(2)" class="border_with_drop-shadow" src="images/ai_starter_kit_2.png" width="444"></a></p>
  <p>&nbsp;</p>
  <p>カメラ初期設定についてはカメラ毎の取扱説明書をご確認ください。</p>
  <p>カメラのIPアドレスを確認・設定できる下記ツールを事前に入手しておくと便利です。</p>
  <ul>
    <li>
      <a href="https://connect.panasonic.com/jp-ja/products-services_security_support_specifications-manuals-firms-tool_2014040315191048" target="_blank">
      IP簡単設定ソフトウェア</a>&nbsp;（日本国内）</li>
    <li>
      <a href="https://bizpartner.panasonic.net/public/file/ip-setting-software" target="_blank">
      IP Setting Software</a>&nbsp;&nbsp;&nbsp;&nbsp; （グローバル）</li>
  </ul>
</section>

<p>&nbsp;</p>
<hr>
<p>&nbsp;</p>

<section>
	<h2> <a name="1._MJPEG 表記仕様">1. MJPEG 表記仕様</a></h2>
	<h4>[概要]</h4>
  	<p> MJPEG で接続するための表記を以下に記載します。</p>
    <p> 「ネットワークカメラCGIコマンドインターフェース仕様書 統合版」<span class="super">[1]</span> で下記に記載されている情報を元に加筆しています。</p>
    <ul>
      <li>ネットワークカメラCGIコマンドインタフェース仕様ver.5.19.pdf： 「3.13 動画像取得(Motion JPEG 形式取得：リアルタイム) (nphMotionJpeg)」</li>
    </ul>
    <p>&nbsp;</p>
    <p><span class="cpp-source">http://&lt;user-id&gt;:&lt;user-password&gt;@&lt;カメラのIPアドレス&gt;/nphMotionJpeg?Resolution=&lt;解像度&gt;&amp;Quality=&lt;品質&gt;&amp;Framerate=&lt;フレームレート&gt;</span></p>
    <p>&nbsp;</p>
    <p>(具体例)</p>
    
    <blockquote>
      http://admin:password@192.168.0.10/nphMotionJpeg?Resolution=1920x1080&amp;Quality=Standard&amp;Framerate=15</blockquote>
    
    <p>&nbsp;</p>
    <p class="auto-style3"><strong>注意事項：</strong></p>
    <ul>
      <li>実験してみたところ、ストリーム(1)～(4) を On にしていると MJPEG の配信性能が落ちる様子です。フレームレートを例えば 15 
      と設定しても最高 5fps ぐらいになるようです。<br>
      カメラの設定にて、ストリーム(1)～(4)を Off、にすることで 15fps 
      の動作もできているように見えます。</li>
    </ul>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
</section>
<p>&nbsp;</p>

<section>
	<h2> <a name="2. i-PRO カメラと MJPEG 接続して映像を表示してみる">2. i-PRO カメラと MJPEG 接続して映像を表示してみる</a></h2>
	<h4>[概要]</h4>
    <p>とりあえず映像を取得してPC画面に表示するまでをやってみます。</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
	  <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
  <p>&nbsp;</p>
  <h3><a name="2-1._方法1">2-1. 方法1</a></h3>
  <p>まずは簡単な方法から。RTSP のコードとほとんど同じ内容で実現できました。</p>
  <p>&nbsp;</p>
  <h4>[プログラム]</h4>
    <p> プログラムを終了する方法を実装していません。コンソール上で [ctrl]+[c] して終了してください。</p>
    <p>&nbsp;</p>
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_1_1.py" target="_blank">connect_with_mjpeg_1_1.py</a>&quot;]</p>
  
	<pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG(Motion JPEG).
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    Let's try first. (Method 1)
    まずはやってみる (方式１)

[library install]
    cv2:    pip install opencv-python
'''

import cv2

user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  15               # Frame rate

# URL
url = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"
cap = cv2.VideoCapture(url)


while True:
    try:
        ret, frame = cap.read()
        if ret == True:
            # Please modify the value to fit your PC screen size.
            frame2 = cv2.resize(frame, (1280, 720))
            
            # Display video.
            cv2.imshow(winname, frame2)

        cv2.waitKey(1)      # necessary to display the video by imshow ()

    except KeyboardInterrupt:
        # Press '[ctrl] + [c]' on the console to exit the program.
        print("KeyboardInterrupt")
        break

cap.release()
cv2.destroyAllWindows()</pre>

  <p>&nbsp;</p>
  <p>上記プログラムを動かしてみます。</p>
  <p>Windows ではこんな感じで実行します。</p>
  <pre style="width: 500px; color: #FFFFFF; background-color: #000000">$ <strong>python</strong> connect_with_mjpeg_1.py</pre>
  <p>&nbsp;</p>
  <p>Linux はこんな感じで実行します。</p>
  <pre style="width: 500px; color: #FFFFFF; background-color: #000000">$ <strong>python3</strong> connect_with_mjpeg_1.py</pre>
  <p>&nbsp;</p>
  <p>Windows環境で複数の Python バージョンをインストールしている場合、下図のような感じで実行バージョンを指定することもできます。<br>
  こちらはバージョン 3.10 の Python で実行する例です。</p>
  <pre style="width: 500px; color: #FFFFFF; background-color: #000000;">$ <strong style="box-sizing: inherit">py -3.10</strong> connect_with_mjpeg_1.py</pre>
  <p>&nbsp;</p>

  <p>上記プログラムを動かした様子を動画で示します。</p>
  <p>こんなに簡単なプログラムでとても快適な映像表示を実現することができました。</p>
  <p>[注意] 上記でも記載しましたが、カメラ側の設定でストリーム(1)～(4)を Off にすることで滑らかな映像表示を実現できました。On 
  のままでもプログラム自体は動作しますが、5fps 程度の映像となりました。</p>
  
  <video controls muted autoplay="y" loop="y" width="800">
    <source src="connect_with_mjpeg/mjpeg_first_30fps.mp4" type="video/mp4">
    動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。
  </video>
  <p>[動画] MJPEG でカメラと接続して映像表示した様子 (30fps) （注意：ストリーム1～4 を全て Off に設定しています）</p>
  
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  
  <h3><a name="2-2._方法2">2-2. 方法2</a></h3>
  <p>下記方法でも MJPEG で接続して映像表示できます。記事[2]を参考に作成してみました。</p>
  <p>&nbsp;</p>
  
  <h4>[プログラム]</h4>
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_1_2.py" target="_blank">connect_with_mjpeg_1_2.py</a>&quot;]</p>
  
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG(Motion JPEG).
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    Let's try first. (Method 2)
    まずはやってみる（方式２）

[library install]
    cv2:    pip install opencv-python
'''

import cv2
import numpy as np
import urllib.request as rq


user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  15               # Frame rate

# URL
url = f"http://{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"


def set_digest_auth(uri, user, passwd):
    '''
    [abstract]
        Authenticate with the IP camera.

    [params]
        uri:      CGI command for start mjpeg stream.
        user:     user-id for camera.
        passwd:   user-password for camera.
    '''
    pass_mgr = rq.HTTPPasswordMgrWithDefaultRealm()
    pass_mgr.add_password(realm=None, uri=uri, user=user, passwd=passwd)
    auth_handler = rq.HTTPDigestAuthHandler(pass_mgr)
    opener = rq.build_opener(auth_handler)
    rq.install_opener(opener)


set_digest_auth(url, user_id, user_pw)
stream = rq.urlopen(url)

bytes = bytes()
while True:
    try:
        bytes += stream.read(1024)
        a = bytes.find(b'\xff\xd8')     # SOI  (Start of Image)  0xFFD8
        b = bytes.find(b'\xff\xd9')     # EOI  (End   of Image)  0xFFD9
        if a != -1 and b != -1:
            jpg = bytes[a:b+2]
            bytes = bytes[b+2:]

            # Convert binary data to ndarray type.
            img_buf = np.frombuffer(jpg, dtype=np.uint8)

            # Decode ndarray data to OpenCV format image data.
            frame = cv2.imdecode(img_buf, cv2.IMREAD_UNCHANGED)

            # Please modify the value to fit your PC screen size.
            frame2 = cv2.resize(frame, (1280, 720))

            # Display video.
            cv2.imshow(winname, frame2)
            cv2.waitKey(1)      # necessary to display the video by imshow ()

    except KeyboardInterrupt:
        # Press '[ctrl] + [c]' on the console to exit the program.
        print("KeyboardInterrupt")
        break

cv2.destroyAllWindows()</pre>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    
</section>

<section>
  <h2><a name="3.プログラムを改善する">3.プログラムを改善する</a></h2>
	<h4>[概要]</h4>
  <p>前章で作成したプログラムはとても簡単に作成できましたが、いろいろと課題がありました。<br>とりあえず下記３つの課題を解決してみます。</p>
  <p>&nbsp;</p>
  <p><span class="auto-style3"><strong>課題１</strong></span><br>プログラムを起動するたびにウィンドウ位置が変わる。場合によっては画面外へ表示する場合もあって不便。<br>
  適当に画面内に収まる場所に表示してほしい。<br>⇨ 指定する場所にウィンドウを表示するようにします。</p>
  <p>&nbsp;</p>
  <p><span class="auto-style3"><strong>課題２</strong></span><br>プログラムを終了するのが大変。<br>ウィンドウ右上の[x]を押すとウィンドウがいったん消えるが、すぐに再表示されて終われない。<br>⇨ 
  ウィンドウ右上の[x]ボタンでプログラムを終了できるようにします。</p>
  <p>&nbsp;</p>
  <p><span class="auto-style3"><strong>課題３</strong></span><br>同様に、任意のキー入力でプログラムを終了できるとうれしい。<br>⇨ "q" キー押下でプログラムを終了できるようにします。</p>
  <p>&nbsp;</p>
    <p>&nbsp;</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
	  <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>

	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
  <p>&nbsp;</p>
  <h4>[プログラム]</h4>
  <p>&nbsp;</p>
  
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_2.py" target="_blank">connect_with_mjpeg_2.py</a>&quot;]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG(Motion JPEG).
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    Let's improve the three issues of "connect_with_mjpeg_1_1.py".
    "connect_with_mjpeg_1_1.py" で確認した下記３つの課題を改善してみます。

    [Issues 1]
    Specifies the position where the window is displayed.
    ウィンドウを指定する場所に表示するようにします。
    [Issues 2]
    Modify the program so that you can exit the program by clicking the [x] button.
    ウィンドウ右上の[x]ボタンでプログラムを終了できるようにします。
    [Issues 3]
    Modify the program so that you can exit the program by pressing the [q] key.
    "q" キー押下でプログラムを終了できるようにします。

[Library install]
    cv2:    pip install opencv-python
'''

import cv2

user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  15               # Frame rate

# URL
url = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"
cap = cv2.VideoCapture(url)

<span class="auto-style2">#</span>
<span class="auto-style2">windowInitialized = False</span>

<span class="auto-style2"># Exception definition</span>
<span class="auto-style2">BackendError = type('BackendError', (Exception,), {})</span>

<span class="auto-style2">def IsWindowVisible(winname):</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    [Abstract]</span>
<span class="auto-style2">        Check if the target window exists.</span>
<span class="auto-style2">        対象ウィンドウが存在するかを確認する。</span>
<span class="auto-style2">    [Param]</span>
<span class="auto-style2">        winname :       Window title</span>
<span class="auto-style2">    [Return]</span>
<span class="auto-style2">        True :          exist</span>
<span class="auto-style2">                        存在する</span>
<span class="auto-style2">        False :         not exist</span>
<span class="auto-style2">                        存在しない</span>
<span class="auto-style2">    [Exception]</span>
<span class="auto-style2">        BackendError :</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    try:</span>
<span class="auto-style2">        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)</span>
<span class="auto-style2">        if ret == -1:</span>
<span class="auto-style2">            raise BackendError('Use Qt as backend to check whether window is visible or not.')</span>

<span class="auto-style2">        return bool(ret)</span>

<span class="auto-style2">    except cv2.error:</span>
<span class="auto-style2">        return False</span>


while True:
    try:
        ret, frame = cap.read()
        if ret == True:
            # Please modify the value to fit your PC screen size.
            frame2 = cv2.resize(frame, (1280, 720))

            # Display video.
            cv2.imshow(winname, frame2)

<span class="auto-style2">            if windowInitialized==False:</span>
<span class="auto-style2">                # Specify window position only once at startup.</span>
<span class="auto-style2">                cv2.moveWindow(winname, 100, 100)</span>
<span class="auto-style2">                windowInitialized = True</span>

<span class="auto-style2">        # Press the "q" key to finish.</span>
<span class="auto-style2">        k = cv2.waitKey(1) &amp; 0xff   # necessary to display the video by imshow ()</span>
<span class="auto-style2">        if k == ord("q"):</span>
<span class="auto-style2">            break</span>
<span class="auto-style2">        </span>
<span class="auto-style2">        # Exit the program if there is no specified window.</span>
<span class="auto-style2">        if not IsWindowVisible(winname):</span>
<span class="auto-style2">            break</span>

    except KeyboardInterrupt:
        # Press '[ctrl] + [c]' on the console to exit the program.
        print("KeyboardInterrupt")
        break

cap.release()
cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>


<section>
  <h2><a name="4. OpenCV で顔検知を加えてみる">4. OpenCV で顔検知を加えてみる</a></h2>
  <p>MJPEG の実装でも OpenCV による顔検知を実装してみます。</p>
  <p>MJPEG 接続では映像情報は受け身です。このため高解像度、高フレームレートの映像を処理したとき、OpenCV の処理が追いつくかが心配な部分です。</p>
  <p>&nbsp;</p>
  <p>下記 URL からファイル "haarcascade_frontalface_alt2.xml" 
  を入手してプログラムと同じ場所に保存する必要があります。</p>
  <p>
  <a href="https://github.com/opencv/opencv/tree/master/data/haarcascades" target="_blank">
  https://github.com/opencv/opencv/tree/master/data/haarcascades</a> </p>
  <p>xml ファイル取得方法は <a href="how_to_get_xml_file.html">こちら</a> を参照ください</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
	  <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>

	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
  <p>&nbsp;</p>
  <h3><a name="4-1._まずは単純にやってみる">4-1. まずは単純にやってみる</a></h3>
  <p>とにかくまずはやってみます。</p>
  <p>映像を受信するたびの OpenCV で毎回認識処理を行ってみます。</p>
  <p>&nbsp;</p>
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_3_1.py" target="_blank">connect_with_mjpeg_3_1.py</a>&quot;]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG(Motion JPEG).
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    Let's add face detection using OpenCV.
    OpenCV を使って顔検知を追加してみます

[Library install]
    cv2:    pip install opencv-python

[OpenCV]
    Get the file "haarcascade_frontalface_alt2.xml" from the URL below.
    下記URLからファイル "haarcascade_frontalface_alt2.xml" を入手するしてください。
    https://github.com/opencv/opencv/tree/master/data/haarcascades
'''

import cv2

user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  15               # Frame rate

# URL
url = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"

# Exception definition.
BackendError = type('BackendError', (Exception,), {})

def IsWindowVisible(winname):
    '''
    [Abstract]
        Check if the target window exists.
        対象ウィンドウが存在するかを確認する。
    [Param]
        winname :       Window title
    [Return]
        True :          exist
                        存在する
        False :         not exist
                        存在しない
    [Exception]
        BackendError :
    '''
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False

<span class="auto-style2">def DetectFaces(cascade, image):</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    [Abstract]</span>
<span class="auto-style2">        Detect faces and return recognition result.</span>
<span class="auto-style2">        顔検知して認識結果を返す</span>
<span class="auto-style2">    [Param]</span>
<span class="auto-style2">        cascade :       CascadeClassifier object in OpenCV format.</span>
<span class="auto-style2">        image :         Image in OpenCV format.</span>
<span class="auto-style2">    [Return]</span>
<span class="auto-style2">        Detection result.</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    # Convert to grayscale image for face detection.</span>
<span class="auto-style2">    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span>

<span class="auto-style2">    # Detect faces from image.</span>
<span class="auto-style2">    face_list = cascade.detectMultiScale(img_gray, minSize=(100, 100))</span>

<span class="auto-style2">    # Return result.</span>
<span class="auto-style2">    return face_list</span>


<span class="auto-style2">def DrawFaceRectangles(image, face_list):</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    [Abstract]</span>
<span class="auto-style2">        Draw red frames on the image according to the detection result face_list.</span>
<span class="auto-style2">        検出結果 face_list にしたがって、image 上に赤枠を描画する。</span>
<span class="auto-style2">    [Param]</span>
<span class="auto-style2">        image :         Image in OpenCV format.</span>
<span class="auto-style2">        face_list :     List of detected face frames.</span>
<span class="auto-style2">    [Return]</span>
<span class="auto-style2">        None</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    # Draw red frames for the number of detected faces.</span>
<span class="auto-style2">    if len(face_list) != 0:</span>
<span class="auto-style2">        for (pos_x, pos_y, w, h) in face_list:</span>
<span class="auto-style2">            print(f"pos_x = {pos_x}, pos_y = {pos_y}, w = {w}, h = {h}")</span>
<span class="auto-style2">            cv2.rectangle(image, (pos_x, pos_y), (pos_x + w, pos_y + h), (0,0,255), thickness=5)</span>


'''
[Abstract]
    main 関数
'''
if __name__ == '__main__':

    cap = cv2.VideoCapture(url)

    #
    windowInitialized = False

<span class="auto-style2">    # haarcascade file for opencv cascade classification.</span>
<span class="auto-style2">    cascade_file = "haarcascade_frontalface_alt2.xml"       # face</span>
<span class="auto-style2">    #cascade_file = "haarcascade_eye.xml"                   # eye ?</span>
<span class="auto-style2">    #cascade_file = "haarcascade_eye_tree_eyeglasses.xml"   # eye ?</span>
<span class="auto-style2">    cascade = cv2.CascadeClassifier(cascade_file)</span>

    while True:
        try:
            ret, frame = cap.read()
            if ret == True:
<span class="auto-style2">                # Face detection.</span>
<span class="auto-style2">                face_list = DetectFaces(cascade, frame)</span>

<span class="auto-style2">                # Draw face rectangles.</span>
<span class="auto-style2">                DrawFaceRectangles(frame, face_list)</span>

                # Please modify the value to fit your PC screen size.
                frame2 = cv2.resize(frame, (1280, 720))
                
                # Display video.
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # Specify window position only once at startup.
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True

            # Press the "q" key to finish.
            k = cv2.waitKey(1) &amp; 0xff   # necessary to display the video by imshow ()
            if k == ord("q"):
                break
            
            # Exit the program if there is no specified window.
            if not IsWindowVisible(winname):
                break

        except KeyboardInterrupt:
            # Press '[ctrl] + [c]' on the console to exit the program.
            print("KeyboardInterrupt")
            break

    cap.release()
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p class="auto-style3"><strong>結果：</strong></p>
  <p>私のゲーミングPCではこれでもそこそこ動作しました。思ったより動く、という感想です。</p>
  <p>が、それでもだんだん映像が遅れていきます。<br>顔検知処理と描画の部分をコメントアウトすると、映像表示の遅れはなくなります。<br>
  やはり顔検知処理は PC にとって結構重たい処理のようです。</p>
  <p>ちょっと残念。何か改善策を考えてみたいところです。</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <h3><a name="4-2._顔検知部分を別プロセスの処理にしてみる">4-2. 顔検知部分を別プロセスの処理にしてみる</a></h3>
  <p>
  そこで、顔検知部分を別タスクに分離することで、映像受信と映像デコード処理を止めずにできるだけ顔検知をやってみる、という感じにプログラムを修正してみます。</p>
  <p>別タスクというと一般的なプログラムでは "スレッド" というテクニックを使いますが、どうやら CPython 
  と呼ばれるプラットフォームの場合はスレッドは複数の処理を同時に実行してくれないらしいです。そこで、ここでは別プロセスを起動し、キューと呼ばれるIOで情報をやり取りしてみます。</p>
  <p>&nbsp;</p>
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_3_2.py" target="_blank">connect_with_mjpeg_3_2.py</a>&quot;]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG(Motion JPEG).
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    Let's add face detection using OpenCV.
    Improve performace of "connect_with_mjpeg_3_1.py" by creating a face detection process.

    OpenCV を使って顔検知を追加してみます
    "connect_with_mjpeg_3_1.py" で確認したパフォーマンス問題を、顔検知処理を別プロセスにすることで改善してみます。

[Library install]
    cv2:    pip install opencv-python

[OpenCV]
    Get the file "haarcascade_frontalface_alt2.xml" from the URL below.
    下記URLからファイル "haarcascade_frontalface_alt2.xml" を入手するしてください。
    https://github.com/opencv/opencv/tree/master/data/haarcascades
'''

import cv2
<span class="auto-style2">import multiprocessing as mp</span>
<span class="auto-style2">from queue import Empty</span>


user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  30               # Frame rate

# URL
url = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"

<span class="auto-style2"># haarcascade file for opencv cascade classification.</span>
<span class="auto-style2">cascade_file = "haarcascade_frontalface_alt2.xml"       # face</span>
<span class="auto-style2">#cascade_file = "haarcascade_eye.xml"                   # eye ?</span>
<span class="auto-style2">#cascade_file = "haarcascade_eye_tree_eyeglasses.xml"   # eye ?</span>
<span class="auto-style2">cascade = cv2.CascadeClassifier(cascade_file)</span>


# Exception definition.
BackendError = type('BackendError', (Exception,), {})

def IsWindowVisible(winname):
    '''
    [Abstract]
        Check if the target window exists.
        対象ウィンドウが存在するかを確認する。
    [Param]
        winname :       Window title
    [Return]
        True :          exist
                        存在する
        False :         not exist
                        存在しない
    [Exception]
        BackendError :
    '''
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False


def DetectFaces(cascade, image):
    '''
    [Abstract]
        Detect faces and return recognition result.
        顔検知して認識結果を返す
    [Param]
        cascade :       CascadeClassifier object in OpenCV format.
        image :         Image in OpenCV format.
    [Return]
        Detection result.
    '''
    # Convert to grayscale image for face detection.
    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Detect faces from image.
    face_list = cascade.detectMultiScale(img_gray, minSize=(100, 100))

    # Return result.
    return face_list


<span class="auto-style2">def DetectFacesProcess(q1, q2):</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    [Abstract]</span>
<span class="auto-style2">        Face detection process.</span>
<span class="auto-style2">    [Param]</span>
<span class="auto-style2">        q1 :        [i] Queue to save the image to detect the face.</span>
<span class="auto-style2">        q2 :        [o] Queue to save the result of face detection.</span>
<span class="auto-style2">    [Return]</span>
<span class="auto-style2">        無し</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    while True:</span>
<span class="auto-style2">        try:</span>
<span class="auto-style2">            image = q1.get(True, 10)</span>

<span class="auto-style2">            # Termination check: If type(image) is "int" and the value is -1, it ends.</span>
<span class="auto-style2">            if type(image) == int:</span>
<span class="auto-style2">                if image == -1:</span>
<span class="auto-style2">                    break</span>

<span class="auto-style2">            # Do face detection.</span>
<span class="auto-style2">            face_list = DetectFaces(cascade, image)</span>

<span class="auto-style2">            q2.put(face_list)</span>
<span class="auto-style2">        except Empty: # timeout of q1.get()</span>
<span class="auto-style2">            print("Timeout happen.(3)")</span>

<span class="auto-style2">    print("Finish DetectFacesProcess()")   </span> 


def DrawFaceRectangles(image, face_list):
    '''
    [Abstract]
        Draw red frames on the image according to the detection result face_list.
        検出結果 face_list にしたがって、image 上に赤枠を描画する。
    [Param]
        image :         Image in OpenCV format.
        face_list :     List of detected face frames.
    [Return]
        None
    '''
    # Draw red frames for the number of detected faces.
    if len(face_list) != 0:
        for (pos_x, pos_y, w, h) in face_list:
            print(f"pos_x = {pos_x}, pos_y = {pos_y}, w = {w}, h = {h}")
            cv2.rectangle(image, (pos_x, pos_y), (pos_x + w, pos_y + h), (0,0,255), thickness=5)


if __name__ == '__main__':
    '''
    [Abstract]
        main function
    '''
    cap = cv2.VideoCapture(url)

    #
    windowInitialized = False

<span class="auto-style2">    q1 = mp.Queue()</span>
<span class="auto-style2">    q2 = mp.Queue()</span>

<span class="auto-style2">    p = mp.Process(target=DetectFacesProcess, args=(q1, q2))</span>
<span class="auto-style2">    p.start()</span>

    init = False

    while True:
        try:
            ret, frame = cap.read()
            if ret == True:
<span class="auto-style2">                # Pass the image to the face detection process.</span>
<span class="auto-style2">                if (q1.qsize() &lt;= 1) and (q2.qsize() &lt;= 1):</span>
<span class="auto-style2">                    q1.put(frame)</span>

<span class="auto-style2">                # Receive results from face detection processing.</span>
<span class="auto-style2">                if q2.qsize() != 0:</span>
<span class="auto-style2">                    face_list = q2.get()</span>
<span class="auto-style2">                    init = True</span>

<span class="auto-style2">                if init == True:</span>
<span class="auto-style2">                    # Draw face rectangles.</span>
<span class="auto-style2">                    DrawFaceRectangles(frame, face_list)</span>

                # Please modify the value to fit your PC screen size.
                frame2 = cv2.resize(frame, (1280, 720))
                
                # Display video.
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # Specify window position only once at startup.
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True

            # Press the "q" key to finish.
            k = cv2.waitKey(1) &amp; 0xff   # necessary to display the video by imshow ()
            if k == ord("q"):
                break
            
            # Exit the program if there is no specified window.
            if not IsWindowVisible(winname):
                break

        except KeyboardInterrupt:
            # Press '[ctrl] + [c]' on the console to exit the program.
            print("KeyboardInterrupt")
            break

<span class="auto-style2">    # Terminate process p</span>
<span class="auto-style2">    q1.put(-1)</span>
<span class="auto-style2">    # Waiting for process p to finish</span>
<span class="auto-style2">    p.join()</span>

    print("Finish main()")
    cap.release()
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p class="auto-style3"><strong>結果：</strong></p>
  <p>期待する動作をしてくれるようになりました。</p>
  <p>プロセス起動の引数として cascade を一緒に渡したかったのですが、"cannot pickle object" 
  というエラーを発生して実現できませんでした。残念ながら cascade をグローバル変数へ変更することで問題を回避しています。<br>対応策がわかったら記事をアップデートしたいと思います。</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  
	<video controls muted autoplay="y" loop="y" src="connect_with_mjpeg/mjpeg_opencv_30fps.mp4" width="800px">
	  <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
  </video>

  <p>[動画] OpenCV で顔検知してみた様子 (30fps) （注意：ストリーム1～4 を全て Off に設定しています）</p>
  
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  
</section>

<section>
  <h2><a name="5._連番の_JPEG_ファイルで保存する">5. 連番の JPEG ファイルで保存する</a></h2>
  <p>受信した画像を 1 から始まる連番のファイル名 (image_NNNNNN.jpg) で JPEG ファイルとして保存してみます。</p>
  <p>&nbsp;</p>
  <ul>
    <li>JPEG 情報はカメラから受信したデータをそのままに保存するようにします。</li>
    <li>"image" という名称でフォルダを作成し、ここに "image_000001.jpg" というようなファイル名で画像を保存します。</li>
  </ul>

	<p>&nbsp;</p>

	<h4>[評価環境]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
	  <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>

	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
  <p>&nbsp;</p>
  <p>[プログラムソース "<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_4.py" target="_blank">connect_with_mjpeg_4.py</a>"]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG(Motion JPEG).
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    Save the received JPEG image as a file.
    Add a 6-digit number to the end of the file name and save it as a serial number.

    受信した JPEG 画像をファイル保存します。
    ファイル名の末尾に６ケタの番号を付けて連番で保存します。

[Library install]
    cv2:    pip install opencv-python
'''

import cv2
import numpy as np
import os
import urllib.request as rq

user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  5                # Frame rate
pathOut     = 'image'           # Image file save folder name

# URL
url = f"http://{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"

# Exception definition
BackendError = type('BackendError', (Exception,), {})

def IsWindowVisible(winname):
    '''
    [Abstract]
        Check if the target window exists.
        対象ウィンドウが存在するかを確認する。
    [Param]
        winname :       Window title
    [Return]
        True :          exist
                        存在する
        False :         not exist
                        存在しない
    [Exception]
        BackendError :
    '''
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False


def set_digest_auth(uri, user, passwd):
    '''
    [abstract]
        Authenticate with the IP camera.

    [params]
        uri:      CGI command for start mjpeg stream.
        user:     user-id for camera.
        passwd:   user-password for camera.
    '''
    pass_mgr = rq.HTTPPasswordMgrWithDefaultRealm()
    pass_mgr.add_password(realm=None, uri=uri, user=user, passwd=passwd)
    auth_handler = rq.HTTPDigestAuthHandler(pass_mgr)
    opener = rq.build_opener(auth_handler)
    rq.install_opener(opener)


<span class="auto-style2">def SaveBinaryData(data, filename):</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    [Abstract]</span>
<span class="auto-style2">        Save the binary data with the specified file name.</span>
<span class="auto-style2">    [Param]</span>
<span class="auto-style2">        data :      binary data.</span>
<span class="auto-style2">        filename :  filename.</span>
<span class="auto-style2">    '''</span>
<span class="auto-style2">    fout = open(filename, 'wb')</span>
<span class="auto-style2">    fout.write(data)</span>
<span class="auto-style2">    fout.close()</span>


if __name__ == '__main__':
    '''
    [Abstract]
        main function.
    '''
    windowInitialized = False
<span class="auto-style2">    count = 0</span>
<span class="auto-style2">    if not os.path.exists(pathOut):</span>
<span class="auto-style2">        os.mkdir(pathOut)</span>

    set_digest_auth(url, user_id, user_pw)
    stream = rq.urlopen(url)

    bytes = bytes()
    while True:
        try:
            bytes += stream.read(1024)
            a = bytes.find(b'\xff\xd8')     # SOI (Start of Image)  0xFFD8
            b = bytes.find(b'\xff\xd9')     # EOI (End   of Image)  0xFFD9
            if a != -1 and b != -1:
                jpg = bytes[a:b+2]
                bytes = bytes[b+2:]

<span class="auto-style2">                # Save jpeg file.</span>
<span class="auto-style2">                count += 1</span>
<span class="auto-style2">                filename = os.path.join(pathOut, 'image_{:06d}.jpg'.format(count))</span>
<span class="auto-style2">                SaveBinaryData(jpg, filename)</span>

                # Convert binary data to ndarray type.
                img_buf = np.frombuffer(jpg, dtype=np.uint8)

                # Decode ndarray data to OpenCV format image data.
                frame = cv2.imdecode(img_buf, cv2.IMREAD_UNCHANGED)

                # Please modify the value to fit your PC screen size.
                frame2 = cv2.resize(frame, (1280, 720))

                # Display video.
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # Specify window position only once at startup.
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True

                # Press the "q" key to finish.
                k = cv2.waitKey(1) &amp; 0xff   # necessary to display the video by imshow ()
                if k == ord("q"):
                    break

                # Exit the program if there is no specified window.
                if not IsWindowVisible(winname):
                    break

        except KeyboardInterrupt:
            # Press '[ctrl] + [c]' on the console to exit the program.
            print("KeyboardInterrupt")
            break
    
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>

<p>&nbsp;</p>

<section>
  <h2><a name="6._映像切断時の再接続処理を追加">6. 映像切断時の再接続処理を追加</a></h2>
  <p>ここまでのプログラムは、カメラとの接続が30秒以上切断すると接続が復活しませんでした。<br>OpenCV の read() 
  関数のタイムアウトは30秒となっているようです。30秒以内に接続が復活していれば自動的に再接続してくれるのですが、30秒を超えると自動的には復活しません。</p>
  <p>"connect_with_rtsp_2.py" を元に再接続処理を追加してこの問題を解決してみたいと思います。</p>
  <p>&nbsp;</p>
    <div class="status_ok">
      <div>
      </div>
      <div>
        <p><strong>ポイント</strong></p>
          <ul>
            <li>read() の戻り値が False であったら再接続を行います。</li>
            <li>release() で切断後、cv2.VideoCapture() で再接続します。</li>
          </ul>
      </div>
    </div>
  <p>&nbsp;</p>
    <div class="status_information">
      <div>
      </div>
      <div>
        <p><strong>NOTE</strong></p>
        <ul>
          <li>切断の試験はカメラの電源をOff/Onする、通信をOff/Onする、などで試験してください。</li>
          <li>カメラとの接続が正常状態に戻ってから再接続までは最長30秒かかります。気長にお待ちください。</li>
          <li>read() のタイムアウト時間を変更する API を確認できませんでした。おそらく固定値で変更できないと思われます。</li>
    		</ul>
      </div>
    </div>
    <p>&nbsp;</p>
  <p>&nbsp;</p>
  <h4>[評価環境]</h4>
  <table>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>言語 :</td>
      <td>Python,</td>
      <td>3.10.4 </td>
    </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>OS :</td>
      <td>Windows 11 home,</td>
      <td>21H2</td>
    </tr>
    <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
  </table>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>[プログラムソース "<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_5.py" target="_blank">connect_with_mjpeg_5.py</a>"]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with RTSP.
    RTSP で i-PRO カメラと接続してみる。

[Details]
    Add reconnection when video is disconnected to "connect_with_mjpeg_2.py".
    映像切断時の再接続処理を"connect_with_mjpeg_2.py"へ追加する。

[Library install]
    cv2:    pip install opencv-python
'''

from nturl2path import url2pathname
import cv2

user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  15               # Frame rate
url         = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"

#
windowInitialized = False

# Exception definition.
BackendError = type('BackendError', (Exception,), {})

def IsWindowVisible(winname):
    '''
    [Abstract]
        Check if the target window exists.
        対象ウィンドウが存在するかを確認する。
    [Param]
        winname :       Window title
    [Return]
        True :          exist
                        存在する
        False :         not exist
                        存在しない
    [Exception]
        BackendError :
    '''
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False


if __name__ == '__main__':
    '''
    [Abstract]
        main function.
    '''
    cap = cv2.VideoCapture(url)

    while True:
        try:
            ret, frame = cap.read()
            if ret == True:
                # Please modify the value to fit your PC screen size.
                frame2 = cv2.resize(frame, (1280, 720))
                # Display video.
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # Specify window position only once at startup.
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True
<span class="auto-style2">            else:</span>
<span class="auto-style2">                print("cap.read() return False.")</span>
<span class="auto-style2">                # The timeout period seems to be 30 seconds.</span>
<span class="auto-style2">                # And there seems to be no API to change the timeout value.</span>

<span class="auto-style2">                # Reconnect</span>
<span class="auto-style2">                cap.release()</span>
<span class="auto-style2">                cap = cv2.VideoCapture(url)</span>

            # Press the "q" key to finish.
            k = cv2.waitKey(1) &amp; 0xff   # necessary to display the video by imshow ()
            if k == ord("q"):
                break
            
            # Exit the program if there is no specified window.
            if not IsWindowVisible(winname):
                break
        
        except KeyboardInterrupt:
            # Press'[ctrl] + [c]' on the console to exit the program.
            print("KeyboardInterrupt")
            break

    cap.release()
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>

<p>&nbsp;</p>

<section>
  <h2><a name="7._GUIで映像表示してみる（tkinter）">7. GUIで映像表示してみる（tkinter）</a></h2>
  <p>ここまでのプログラムは全てOpenCVが作成するウィンドウ表示でした。<br>ここでは独自の GUI を作成してここに映像表示する例を示します。</p>
  <p>GUI 表示の実現方法もいろいろありますが、ここでは Python 標準の tkinter を使用してみます。</p>
  <p>&nbsp;</p>
  <p>tkinter のインストール方法は環境により異なるようです。各人の環境にあった方法をインターネットで調べて実施してください。</p>
  <p>&nbsp;</p>
    <div class="status_ok">
      <div>
      </div>
      <div>
        <p><strong>ポイント</strong></p>
        <ul>
          <li>tkinter で動画を表示するときは、after() 関数で繰り返し処理を行います。</li>
          <li>tkinter で表示するために ImageTk.PhotoImage という型に変換する必要があります。<br>numpy.ndarray → 
          PIL.Image → ImageTk.PhotoImage という順に変換して tkinter で表示します。</li>
          <li>OpenCVの画像は BGR の並び順になっています。tkinker で表示するために BGR データを RGB へ並び替える必要があります。</li>
        </ul>
      </div>
    </div>
  <p>&nbsp;</p>
  <p>「<a href="connect_with_rtsp.html#7-3. メニュー・ボタンを追加して GUI アプリらしくしてみる">RTSP で画像を取得する ： 7-3. メニュー・ボタンを追加して GUI 
  アプリらしくしてみる</a>」で既に 
  GUI 版を作成済みなので、プログラム "connect_with_rtsp_6_3.py" 
  をベースに変更箇所のみをわかるように以下で記載します。ほとんど同じ内容で実現できます。</p>
  <p>&nbsp;</p>
  <h4>[評価環境]</h4>
  <table>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>言語 :</td>
      <td>Python,</td>
      <td>3.10.4 </td>
    </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>Tcl/Tk,</td>
      <td>8.6 </td>
    </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>OS :</td>
      <td>Windows 11 home,</td>
      <td>21H2</td>
    </tr>
    <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
  </table>
  <p>&nbsp;</p>
  <p>[プログラムソース "<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_6.py" target="_blank">connect_with_mjpeg_6.py</a>"]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG.
    MJPEG で i-PRO カメラと接続してみる。

[Details]
    Display the video with GUI using tkinter.
    Add menus and buttons to make it look like a GUI app.
    
    tkinter を使ったGUIで映像を表示します。
    メニューとボタンを追加してGUIアプリらしくします。

    BGR → RGB
    numpy.ndarray → PIL.Image → ImageTk.PhotoImage
    (1) BGR → RGB
    (2) numpy.ndarray → PIL.Image
    (3) PIL.Image → ImageTk.PhotoImage

[Library install]
    cv2:    pip install opencv-python
    PIL :   pip install pillow
'''

import cv2
import time
import tkinter as tk
from tkinter import messagebox
from PIL import Image, ImageTk, ImageOps
import multiprocessing as mp


user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
<span class="auto-style2">resolution  = "1920x1080"       # Resolution</span>
<span class="auto-style2">framerate   =  15               # Frame rate</span>
<span class="auto-style2">url         = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"</span>


class Application(tk.Frame):
    def __init__(self, master = None):
        super().__init__(master)
        self.pack()

        # Window settings.
        self.master.title("Display i-PRO camera with tkinter")      # Window title
        self.master.geometry("800x600+100+100")                     # Window size, position

        # Event registration for window termination.
        self.master.protocol("WM_DELETE_WINDOW", self.on_closing_window)

        # Create menu.
        menubar = tk.Menu(self.master)
        self.master.configure(menu=menubar)
        filemenu = tk.Menu(menubar)
        menubar.add_cascade(label='File', menu=filemenu)
        filemenu.add_command(label='Quit', command = self.on_closing_window)

        # Create button_frame
        self.button_frame = tk.Frame(self.master, padx=10, pady=10, relief=tk.RAISED, bd=2)
        self.button_frame.pack(side = tk.BOTTOM, fill=tk.X)

        # Create quit_button
        self.quit_button = tk.Button(self.button_frame, text='Quit', width=10, command = self.on_closing_window)
        self.quit_button.pack(side=tk.RIGHT)
        
        # Create canvas.
        self.canvas = tk.Canvas(self.master)

        # Add mouse click event to canvas.
        self.canvas.bind('&lt;Button-1&gt;', self.canvas_click)

        # Place canvas.
        self.canvas.pack(expand = True, fill = tk.BOTH)

        # Create image receiving process and queue
        self.imageQueue = mp.Queue()
        self.request = mp.Value('i', 0)     # -1 : Exit ReceiveImageProcess.
                                            #  0 : Normal.
                                            #  1 : Connect camera.
                                            #  2 : Release camera.
        self.p = mp.Process(target=ReceiveImageProcess, args=(self.imageQueue, self.request))
        self.p.start()

        # Raise a video display event (disp_image) after 500m
        self.disp_id = self.after(500, self.disp_image)

    def on_closing_window(self):
        ''' Window closing event. '''

        if messagebox.askokcancel("QUIT", "Do you want to quit?"):
            # Request terminate process self.p.
            self.request.value = -1

            # Waiting for process p to finish
            time.sleep(1)

            # Flash buffer.
            # The program cannot complete p.join() unless the imageQueue is emptied.
            for i in range(self.imageQueue.qsize()):
                pil_image = self.imageQueue.get()

            # Wait for process p to be terminated.
            self.p.join()
            self.master.destroy()
            print("Finish Application.")

    def canvas_click(self, event):
        ''' Event handling with mouse clicks on canvas '''

        if self.disp_id is None:
            # Connect camera.
            self.request.value = 1
            # Display image.
            self.disp_image()

        else:
            # Release camera.
            self.request.value = 2
            # Cancel scheduling
            self.after_cancel(self.disp_id)
            self.disp_id = None

    def disp_image(self):
        ''' Display image on Canvas '''

        # If there is data in the imageQueue, the program receives the data and displays the video.
        num = self.imageQueue.qsize()
        if num &gt; 0:
            if (num &gt; 5):
                num -= 1
            for i in range(num):
                cv_image = self.imageQueue.get()

            # (2) Convert image from ndarray to PIL.Image.
            pil_image = Image.fromarray(cv_image)

            # Get canvas size.
            canvas_width = self.canvas.winfo_width()
            canvas_height = self.canvas.winfo_height()

            # Resize the image to the size of the canvas without changing the aspect ratio.
            # アスペクトを維持したまま画像を Canvas と同じサイズにリサイズ
            pil_image = ImageOps.pad(pil_image, (canvas_width, canvas_height))

            # (3) Convert image from PIL.Image to PhotoImage
            # PIL.Image から PhotoImage へ変換する
            self.photo_image = ImageTk.PhotoImage(image=pil_image)

            # Display image on the canvas.
            self.canvas.create_image(
                canvas_width / 2,       # Image display position (center of the canvas)
                canvas_height / 2,                   
                image=self.photo_image  # image data
                )
            
        else:
            pass

        # Raise a video display event (disp_image) after 1ms.
        self.disp_id = self.after(1, self.disp_image)


def ReceiveImageProcess(imageQueue, request):
    '''
    Receive Image Process.

    Args:
        imageQueue      [o] This process stores the received image data in the imageQueue.
        request         [i] Shared memory for receiving requests from the main process.
                            -1: Terminate process.
                             0: Nothing.
                             1: Connect camera.
                             2: Release camera connection.
    Returns:
        None
    Raises
        None
    '''

    # Connect camera.
    cap = cv2.VideoCapture(url)

    while True:
        if cap != None:
            # Get frame.
            ret, frame = cap.read()

            if ret == True:
                # (1) Convert image from BGR to RGB.
                cv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                if imageQueue.qsize() &lt; 10:
                    imageQueue.put(cv_image)

            else:
                print("cap.read() return False.")
                # The timeout period seems to be 30 seconds.
                # And there seems to be no API to change the timeout value.
                time.sleep(1)

                # Reconnect
                cap.release()
                cap = cv2.VideoCapture(url)
        else:
            time.sleep(0.1)
                
        # Check process termination request.
        if request.value == -1:
            # Terminate process.
            cap.release()
            request.value = 0
            break

        # Check connect request.
        if request.value == 1:
            cap = cv2.VideoCapture(url)
            request.value = 0

        # Check release request.
        if request.value == 2:
            cap.release()
            cap = None
            request.value = 0

    print("Terminate SaveImageProcess().")


if __name__ == "__main__":
    root = tk.Tk()
    app = Application(master = root)
    app.mainloop()</pre>
  <p>&nbsp;</p>
  <p>
    <video controls muted autoplay="y" loop="y" width="800px">
      <source src="connect_with_mjpeg/mjpeg_6.mp4" type="video/mp4">
      動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。
    </video>
  </p>
  <p>[動画] tkinter で作成した GUI アプリ</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>

<p>&nbsp;</p>

<section>
  <h2><a name="ソースコード所在">ソースコード所在</a></h2>
  <p>本ページで紹介のソースコードは、下記 github より取得できます。</p>
  <p>下記 github のソースコードと本ページの内容は差異がある場合があります。</p>
  <p><a href="https://github.com/i-pro-corp/python-examples" target="_blank">i-pro-corp/python-examples: Examples for i-PRO cameras. (github.com)</a></p>
  <p>&nbsp;</p>
</section>

<p>

<br>

</p>

<section>
  <h2><a name="ライセンス">ライセンス</a></h2>
<p>本ページの情報は、特記無い限り下記ライセンスで提供されます。</p>
<div class="license">
    <br>Copyright 2022 i-PRO Co., Ltd.<br><br>Licensed under the Apache License, Version 
    2.0 (the "License");<br>you may not use this file except in compliance with 
    the License.<br>You may obtain a copy of the License at <br><br>&nbsp;&nbsp;&nbsp;
    <a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank">http://www.apache.org/licenses/LICENSE-2.0</a><br><br>
    Unless required by 
    applicable law or agreed to in writing, software <br>distributed under the 
    License is distributed on an "AS IS" BASIS, <br>WITHOUT WARRANTIES OR 
    CONDITIONS OF ANY KIND, either express or implied. <br>See the License for 
    the specific language governing permissions and<br>limitations under the 
    License. <br> <br>
</div>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>


<section>
	<h2><a name="参考">参考</a></h2>
	<ul>
		<li>[1] ネットワークカメラCGIコマンドインターフェース仕様書　統合版<br>
      <a href="https://connect.panasonic.com/jp-ja/products-services_security_support_specifications-manuals-firms-dvlp_2012100910461872" target="_blank">
        https://connect.panasonic.com/jp-ja/products-services_security_support_specifications-manuals-firms-dvlp_2012100910461872</a></li>
    <li>[2] python - How to parse mjpeg http stream from ip camera? - Stack Overflow<br>
      <a href="https://stackoverflow.com/questions/21702477/how-to-parse-mjpeg-http-stream-from-ip-camera" target="_blank">
        https://stackoverflow.com/questions/21702477/how-to-parse-mjpeg-http-stream-from-ip-camera</a></li>
	</ul>
</section>

<p>&nbsp;</p>

<hr>

<p>&nbsp;</p>

<section>
	<h2 style="margin-bottom:5px">変更履歴</h2>
	<table>
	  <tr>
	    <td class="td_history_date">2023/3/1</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">説明および表現を一部更新,</td>
	    <td class="td_history">木下英俊</td>
	  </tr>
	  <tr>
	    <td class="td_history_date">2022/7/20</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">微修正,</td>
	    <td class="td_history">木下英俊</td>
	  </tr>
	  <tr>
	    <td class="td_history_date">2022/5/26</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">新規作成,</td>
	    <td class="td_history">木下英俊 </td>
	  </tr>
	</table>
</section>

<p>&nbsp;</p>
<p><a href="../../index.html" target="_parent">i-PRO - Programming Items トップページ</a></p>
<p><a href="../../privacy_policy.html">プライバシーポリシー</a></p>
<p>&nbsp;</p>

<footer>
	<p><small>&copy; 2022  i-PRO Co., Ltd.</small></p>
</footer>

</body>
</html>
