<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="kinoshita hidetosi (木下英俊)">
  <meta name="description" content="Introducing programming for i-PRO cameras.">
  <meta name="keywords" content="i-PRO">
  
  <!-- キャッシュ無効化 -->
  <meta http-equiv="Cache-Control" content="no-cache">
	
  <!-- タイトル -->
  <title>MJPEGで画像を取得する</title>
	
  <!-- ファビコン -->
  <link rel="shortcut icon" href="../../favicon.ico">

  <!-- CSS -->
  <link href="https://unpkg.com/ress/dist/ress.min.css" rel="stylesheet">
	<link rel="stylesheet" href="../../design.css" type="text/css">
  
	<!-- Start for 'google-code-prettify' -->
	<link href="../../prettify/styles/desert.css" rel="stylesheet" type="text/css">
	<script src="../../prettify/prettify.js" type="text/javascript"></script>
	<!-- End for 'google-code-prettify' -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5DFRG3H0KB"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5DFRG3H0KB');
  </script>  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  
  <style type="text/css">
  .auto-style2 {
    background-color: #484800;
  }
  .super {
    vertical-align: super;
  }
  </style>

</head>

<body onload="prettyPrint();">

<h1>MJPEG で画像を取得する</h1>

<p> &nbsp;</p>
<table style="border: 1px solid #808080; width: 800px; max-width:100%; background-color: #F0F0F0;">
 <tr>
  <td>
    <strong>NOTE</strong><br>
    本ページは i-PRO株式会社 の有志メンバーにより記載されたものです。<br>
    本ページの情報は <a href="#ライセンス">ライセンス</a> に記載の条件で提供されます。
  </tr>
</table>
<p> &nbsp;</p>
<table style="border: 1px solid #808080; width: 800px; max-width:100%; background-color: #F0F0F0;">
  <tr>
    <td>
      <nav>
        <h2> 目次</h2>
        <p>
        <a href="#1._MJPEG 表記仕様">1. MJPEG 表記仕様</a><br>
        <a href="#2. i-PRO カメラと MJPEG 接続して映像を表示してみる">2. i-PRO カメラと MJPEG 接続して映像を表示してみる</a><br>&nbsp;
        <a href="#2-1._方法1">2-1. 方法1</a><br>&nbsp; 
        <a href="#2-2._方法2">2-2. 方法2</a><br>
        <a href="#3.プログラムを改善する">3. プログラムを改善する</a><br>
        <a href="#4. OpenCV で顔検知を加えてみる">4. OpenCV で顔検知を加えてみる</a><br>&nbsp;
        <a href="#4-1._まずは単純にやってみる">4-1. まずは単純にやってみる</a><br>&nbsp;
        <a href="#4-2._顔検知部分を別プロセスの処理にしてみる">4-2. 顔検知部分を別プロセスの処理にしてみる</a><br>
        <a href="#5._連番の_JPEG_ファイルで保存する">5. 連番の JPEG ファイルで保存する</a><br>
        <a href="#6._映像切断時の再接続処理を追加">6.映像切断時の再接続処理を追加</a><br>
        <a href="#7._GUIで映像表示してみる（tkinter）">7.GUIで映像表示してみる（tkinter）</a><br>
        <br>
        <a href="#ソースコード所在">ソースコード所在</a><br>
        <a href="#ライセンス">ライセンス</a><br>
        <a href="#参考">参考</a><br>
        </p>
      </nav>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<p>&nbsp;</p>

<p> i-PRO のカメラ i-PRO mini (WV-S7130)、モジュールカメラ（AIスターターキット）を入手したので、カメラとPCを接続して動作するプログラムを作成してみました。こちらで紹介します。</p>
<p> ここで記載の内容は、ほとんどの i-PRO カメラでそのまま利用できると思いますが未確認です。</p>
<p>&nbsp;</p>
<section>
<p> "i-PRO mini" 紹介： </p>
<ul>
  <li><a href="https://cwc.i-pro.com/pages/i-pro-mini-lp" target="_blank">i-PRO 
  mini</a></li>
  <li>
  <a href="https://cwc.i-pro.com/collections/camera/products/wv-s7130ux" target="_blank">
  i-PRO mini 有線LANモデル WV-S7130UX</a></li>
  <li>
  <a href="https://cwc.i-pro.com/collections/camera/products/wv-s7130wux" target="_blank">
  i-PRO mini 無線LANモデル WV-S7130WUX</a></li>
  <li>
  <a href="https://japancs.i-pro.com/space/DLJP/724085590/WV-S7130UX　i-PRO+mini+有線LANモデル" target="_blank">
  WV-S7130UX　i-PRO mini 有線LANモデル - ダウンロード - i-PRO サポートポータル</a></li>
  <li>
  <a href="https://japancs.i-pro.com/space/DLJP/724086255/WV-S7130WUX　i-PRO+mini+無線LANモデル" target="_blank">
  WV-S7130WUX　i-PRO mini 無線LANモデル - ダウンロード - i-PRO サポートポータル</a></li>
</ul>
<p> 
<a href="images/i-PRO_mini.jpg" target="_blank">
<img alt="" src="images/i-PRO_mini.jpg" class="border_with_drow-shadow" width="348"></a></p>
<p> 
&nbsp;</p>
<p> 
"モジュールカメラ" 紹介：</p>
<ul>
  <li><a href="https://moduca.i-pro.com/space/MCP" target="_blank">Module Camera 
  Product Information - モジュールカメラ｜ポータルサイト (i-pro.com)</a></li>
  <li>
  <a href="https://moduca.i-pro.com/space/MCT/768743132/各種マニュアル" target="_blank">
  各種マニュアル - Module Camera Technical Information - モジュールカメラ｜ポータルサイト (i-pro.com)</a></li>
</ul>
<p> 
<a href="images/ai_starter_kit_1.png" target="_blank">
<img alt="" class="border_with_drow-shadow" src="images/ai_starter_kit_1.png" width="404"></a>
<a href="images/ai_starter_kit_2.png" target="_blank">
<img alt="" class="border_with_drow-shadow" src="images/ai_starter_kit_2.png" width="444"></a></p>
<p> 
&nbsp;</p>
<p> 
カメラ初期設定についてはカメラ毎の取扱説明書をご確認ください。</p>
<p> 
カメラのIPアドレスを確認・設定できる下記ツールを事前に入手しておくと便利です。</p>
 <ul>
  <li>
  <a href="https://connect.panasonic.com/jp-ja/products-services_security_support_specifications-manuals-firms-tool_2014040315191048" target="_blank">
  IP簡単設定ソフトウェア</a>&nbsp;（日本国内）</li>
  <li>
  <a href="https://bizpartner.panasonic.net/public/file/ip-setting-software" target="_blank">
  IP Setting Software</a>&nbsp;&nbsp;&nbsp;&nbsp; （グローバル）</li>
 </ul>
</section>

<p>&nbsp;</p>
<hr>
<p>&nbsp;</p>

<section>
	<h2> <a name="1._MJPEG 表記仕様">1. MJPEG 表記仕様</a></h2>
	<h4>[概要]</h4>
  	<p> MJPEG で接続するための表記を以下に記載します。</p>
    <p> 「ネットワークカメラCGIコマンドインターフェース仕様書 統合版」<span class="super">[1]</span> で下記に記載されている情報を元に加筆しています。</p>
    <ul>
      <li>ネットワークカメラCGIコマンドインタフェース仕様ver.5.19.pdf： 「3.13 動画像取得(Motion JPEG 形式取得：リアルタイム) (nphMotionJpeg)」</li>
    </ul>
    <p>&nbsp;</p>
    <p><span class="cpp-source">http://&lt;user-id&gt;:&lt;user-password&gt;@&lt;カメラのIPアドレス&gt;/nphMotionJpeg?Resolution=&lt;解像度&gt;&amp;Quality=&lt;品質&gt;&amp;Framerate=&lt;フレームレート&gt;</span></p>
    <p>&nbsp;</p>
    <p>(例) <span class="cpp-source">
    http://admin:password@192.168.0.10/nphMotionJpeg?Resolution=1920x1080&amp;Quality=Standard&amp;Framerate=15</span></p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <h3>注意事項</h3>
    <ul>
      <li>実験してみたところ、ストリーム(1)～(4) を On にしていると MJPEG の配信性能が落ちる様子です。フレームレートを例えば 15 
      と設定しても最高 5fps ぐらいになるようです。<br>
      カメラの設定にて、ストリーム(1)～(4)を Off、にすることで 15fps 
      の動作もできているように見えます。</li>
    </ul>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
</section>
<p>&nbsp;</p>

<section>
	<h2> <a name="2. i-PRO カメラと MJPEG 接続して映像を表示してみる">2. i-PRO カメラと MJPEG 接続して映像を表示してみる</a></h2>
	<h4>[概要]</h4>
    <p>とりあえず映像を取得してPC画面に表示するまでをやってみます。</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
	  <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
  <p>&nbsp;</p>
  <h3><a name="2-1._方法1">2-1. 方法1</a></h3>
  <p>まずは簡単な方法から。RTSP のコードとほとんど同じ内容で実現できました。</p>
  <p>&nbsp;</p>
  <h4>[プログラム]</h4>
    <p> プログラムを終了する方法を実装していません。コンソール上で [ctrl]+[c] して終了してください。</p>
    <p>&nbsp;</p>
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_1_1.py" target="_blank">connect_with_mjpeg_1_1.py</a>&quot;]</p>
  
	<pre class="prettyprint linenums lang-py">
'''
[abstract]
    i-PRO mini (WV-S7130W) と接続して映像を表示してみる 
[library install]
 &nbsp; &nbsp;pip install opencv-python 
'''

import cv2

user_id     = "user-id"         # ご使用のカメラ設定に合わせて変更
user_pw     = "password"        # ご使用のカメラ設定に合わせて変更
host        = "192.168.0.10"    # ご使用のカメラ設定に合わせて変更
winname     = "VIDEO"           # ウィンドウタイトル
resolution  = "1920x1080"       # 解像度
framerate   =  15               # フレームレート

# URL
url = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"
cap = cv2.VideoCapture(url) 

while True:
    try:
        ret, frame = cap.read()
        if ret == True:
            # 使っているPC画面に適当に収まる表示大きさへリサイズ
            frame2 = cv2.resize(frame, (1280, 720))
            cv2.imshow(winname, frame2)

        cv2.waitKey(1)    # 注意： imshow() 関数は、この cv2.waitkey() が無いと画面表示してくれない！

    except KeyboardInterrupt:
        # コンソール上で ctrl-c を押すとプログラムを終了する。
        # GUI 上で ctrl-c してもプログラムを終了できない。
        print("KeyboardInterrupt")
        break

cap.release()
cv2.destroyAllWindows()</pre>

    <p>&nbsp;</p>
    <p>上記プログラムを動かしてみます。実行はこんな感じで行います。</p>
    <p><span class="cpp-source"><strong>python</strong> connect_with_mjpeg_1_1.py</span></p>
    <p>&nbsp;</p>
    <p>Windows環境で複数の Python バージョンをインストールしている場合、下図のような感じで実行バージョンを指定することもできます。<br>
    こちらはバージョン 3.10 の Python で実行を指示する例です。</p>
    <p><span class="cpp-source"><strong>py</strong> -3.10 connect_with_mjpeg_1_1.py</span></p>
    <p>&nbsp;</p>
    <p>上記プログラムを動かした様子を動画で示します。</p>
    <p>こんなに簡単なプログラムでとても快適な映像表示を実現することができました。</p>
    <p>[注意] 上記でも記載しましたが、カメラ側の設定でストリーム(1)～(4)を Off にすることで滑らかな映像表示を実現できました。On 
    のままでもプログラム自体は動作しますが、5fps 程度の映像となりました。</p>
    
<video controls muted autoplay="y" loop="y" src="connect_with_mjpeg/mjpeg_first_30fps.mp4" width="800px">
  <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
</video>

  <p>[動画] MJPEG でカメラと接続して映像表示してみた様子 (30fps) （注意：ストリーム1～4 を全て Off に設定しています）</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <h3><a name="2-2._方法2">2-2. 方法2</a></h3>
    <p>下記方法でも MJPEG で接続して映像表示できます。記事[2]を参考に作成してみました。</p>
  <p>&nbsp;</p>
  <h4>[プログラム]</h4>
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_1_2.py" target="_blank">connect_with_mjpeg_1_2.py</a>&quot;]</p>
  
	  <pre class="prettyprint linenums lang-py">
'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG(Motion JPEG).
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    Let's try first.
    まずはやってみる

[library install]
    pip install opencv-python
'''

import cv2
import numpy as np
import urllib.request as rq

user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  15               # Frame rate

# URL
url = f"http://{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&Quality=Standard&Framerate={framerate}"

'''
[abstract]
    IP カメラと認証処理を行います。

[params]
    uri:      mjpeg 開始 CGI コマンド
    user:     IPカメラの user-id
    passwd:   IPカメラの user-password
'''
def set_digest_auth(uri, user, passwd):
    pass_mgr = rq.HTTPPasswordMgrWithDefaultRealm()
    pass_mgr.add_password(realm=None, uri=uri, user=user, passwd=passwd)
    auth_handler = rq.HTTPDigestAuthHandler(pass_mgr)
    opener = rq.build_opener(auth_handler)
    rq.install_opener(opener)


set_digest_auth(url, user_id, user_pw)
stream = rq.urlopen(url)

bytes = bytes()
while True:
    try:
        bytes += stream.read(1024)
        a = bytes.find(b'\xff\xd8')     # SOI スタートマーカ (Start of Image)  0xFFD8
        b = bytes.find(b'\xff\xd9')     # EOI エンドマーカ   (End   of Image)  0xFFD9
        if a != -1 and b != -1:
            jpg = bytes[a:b+2]
            bytes = bytes[b+2:]

            # binary データを ndarray 型へ変換
            img_buf = np.frombuffer(jpg, dtype=np.uint8)

            # バイナリデータをデコードして画像データにする
            frame = cv2.imdecode(img_buf, cv2.IMREAD_UNCHANGED)

            # 使っているPC画面に適当に収まる表示大きさへリサイズ
            frame2 = cv2.resize(frame, (1280, 720))

            # 映像表示
            cv2.imshow(winname, frame2)
            cv2.waitKey(1)    # 注意： imshow() 関数は、この cv2.waitkey() が無いと画面表示してくれない！

    except KeyboardInterrupt:
        # コンソール上で ctrl-c を押すとプログラムを終了する。
        # GUI 上で ctrl-c してもプログラムを終了できない。
        print("KeyboardInterrupt")
        break

cv2.destroyAllWindows()
</pre>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    
</section>

<section>
  <h2><a name="3.プログラムを改善する">3.プログラムを改善する</a></h2>
	<h4>[概要]</h4>
  <p>前章で作成したプログラムはとても簡単に作成できましたが、いろいろと課題がありました。<br>とりあえず下記３つの課題を解決してみます。</p>
  <p>&nbsp;</p>
  <p>課題１<br>プログラムを起動するたびにウィンドウ位置が変わる。場合によっては画面外へ表示する場合もあって不便。<br>
  適当に画面内に収まる場所に表示してほしい。<br>⇨ 指定する場所にウィンドウを表示するようにします。</p>
  <p>&nbsp;</p>
  <p>課題２<br>プログラムを終了するのが大変。<br>ウィンドウ右上の[x]を押すとウィンドウがいったん消えるが、すぐに再表示されて終われない。<br>⇨ 
  ウィンドウ右上の[x]ボタンでプログラムを終了できるようにします。</p>
  <p>&nbsp;</p>
  <p>課題３<br>同様に、任意のキー入力でプログラムを終了できるとうれしい。<br>⇨ "q" キー押下でプログラムを終了できるようにします。</p>
  <p>&nbsp;</p>
    <p>&nbsp;</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
	  <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>

	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
  <p>&nbsp;</p>
  <h4>[プログラム]</h4>
  <p>&nbsp;</p>
  
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_2.py" target="_blank">connect_with_mjpeg_2.py</a>&quot;]</p>
	<pre class="prettyprint linenums lang-py">
'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG(Motion JPEG).
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    Let's improve the three issues of "connect_with_mjpeg_1_1.py".
    "connect_with_mjpeg_1_1.py" で確認した下記３つの課題を改善してみます。

    [Issues 1]
    Specifies the position where the window is displayed.
    ウィンドウを指定する場所に表示するようにします。
    [Issues 2]
    Modify the program so that you can exit the program by clicking the [x] button.
    ウィンドウ右上の[x]ボタンでプログラムを終了できるようにします。
    [Issues 3]
    Modify the program so that you can exit the program by pressing the [q] key.
    "q" キー押下でプログラムを終了できるようにします。

[library install]
    pip install opencv-python
'''

import cv2

user_id     = "user-id"         # ご使用のカメラ設定に合わせて変更
user_pw     = "password"        # ご使用のカメラ設定に合わせて変更
host        = "192.168.0.10"    # ご使用のカメラ設定に合わせて変更
winname     = "VIDEO"           # ウィンドウタイトル
resolution  = "1920x1080"       # 解像度
framerate   =  15               # フレームレート

# URL
url = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}" 
cap = cv2.VideoCapture(url)

<span class="auto-style2">
#</span>
<span class="auto-style2">windowInitialized = False</span>

<span class="auto-style2"># Exception 定義</span>
<span class="auto-style2">BackendError = type('BackendError', (Exception,), {})</span>

<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    対象ウィンドウが存在するかを確認する。</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    winname :       ウィンドウタイトル</span>
<span class="auto-style2">[Return]</span>
<span class="auto-style2">    True :          対象ウィンドウは存在する</span>
<span class="auto-style2">    False :         対象ウィンドウは存在しない</span>
<span class="auto-style2">[Exception]</span>
<span class="auto-style2">    BackendError :  バックエンドで使用している Qt でエラー発生</span>
<span class="auto-style2">'''</span>
<span class="auto-style2">def IsWindowVisible(winname):</span>
<span class="auto-style2">    try:</span>
<span class="auto-style2">        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)</span>
<span class="auto-style2">        if ret == -1:</span>
<span class="auto-style2">            raise BackendError('Use Qt as backend to check whether window is visible or not.')</span>

<span class="auto-style2">        return bool(ret)</span>

<span class="auto-style2">    except cv2.error:</span>
<span class="auto-style2">        return False</span>


while True:
    try:
        ret, frame = cap.read()
        if ret == True:
            frame2 = cv2.resize(frame, (1280, 720))
            cv2.imshow(winname, frame2)

<span class="auto-style2">            if windowInitialized==False:</span>
<span class="auto-style2">                # 最初の起動時のみ表示位置を指定</span>
<span class="auto-style2">                cv2.moveWindow(winname, 100, 100)</span>
<span class="auto-style2">                windowInitialized = True</span>

<span class="auto-style2">        # Press the "q" key to finish.</span>
<span class="auto-style2">        k = cv2.waitKey(1) &amp; 0xff   # necessary to display the video by imshow ()</span>
<span class="auto-style2">        if k == ord("q"):</span>
<span class="auto-style2">            break</span>
<span class="auto-style2">        </span>
<span class="auto-style2">        # 指定ウィンドウが無かったら終了</span>
<span class="auto-style2">        if not IsWindowVisible(winname):</span>
<span class="auto-style2">            break</span>

    except KeyboardInterrupt:
        print("KeyboardInterrupt")
        break

cap.release()
cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>


<section>
  <h2><a name="4. OpenCV で顔検知を加えてみる">4. OpenCV で顔検知を加えてみる</a></h2>
  <p>MJPEG の実装でも OpenCV による顔検知を実装してみます。</p>
  <p>MJPEG 接続では映像情報は受け身です。このため高解像度、高フレームレートの映像を処理したとき、OpenCV の処理が追いつくかが心配な部分です。</p>
  <p>&nbsp;</p>
  <p>下記 URL からファイル "haarcascade_frontalface_alt2.xml" 
  を入手してプログラムと同じ場所に保存する必要があります。</p>
  <p>
  <a href="https://github.com/opencv/opencv/tree/master/data/haarcascades" target="_blank">
  https://github.com/opencv/opencv/tree/master/data/haarcascades</a> </p>
  <p>xml ファイル取得方法は <a href="how_to_get_xml_file.html">こちら</a> を参照ください</p>
	<p> &nbsp;</p>
	
	<h4>[評価環境1]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
	  <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>

	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
	<p>&nbsp;</p>
	
	<h4>[評価環境2]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.8.10 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Ubuntu(WSL),</td>
	    <td>20.04</td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
  <p>&nbsp;</p>
  <h3><a name="4-1._まずは単純にやってみる">4-1. まずは単純にやってみる</a></h3>
  <p>とにかくまずはやってみます。</p>
  <p>映像を受信するたびの OpenCV で毎回認識処理を行ってみます。</p>
  <p>&nbsp;</p>
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_3_1.py" target="_blank">connect_with_mjpeg_3_1.py</a>&quot;]</p>
  <pre class="prettyprint linenums lang-py">'''
[abstract]
    i-PRO mini (WV-S7130W) と接続して映像を表示してみる。
    ここでは opencv を使って顔検知を追加してみます。

[library install]
    pip install opencv-python
'''

import cv2

user_id     = "user-id"         # ご使用のカメラ設定に合わせて変更
user_pw     = "password"        # ご使用のカメラ設定に合わせて変更
host        = "192.168.0.10"    # ご使用のカメラ設定に合わせて変更
winname     = "VIDEO"           # ウィンドウタイトル
resolution  = "1920x1080"       # 解像度
framerate   =  15               # フレームレート

# URL
url = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"

# Exception 定義
BackendError = type('BackendError', (Exception,), {})

'''
[Abstract]
    対象ウィンドウが存在するかを確認する。
[Param]
    winname :       ウィンドウタイトル
[Return]
    True :          対象ウィンドウは存在する
    False :         対象ウィンドウは存在しない
[Exception]
    BackendError :  バックエンドで使用している Qt でエラー発生
'''
def IsWindowVisible(winname):
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False

<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    顔検知して認識結果を返す</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    cascade :       OpenCV の CascadeClassifierオブジェクト</span>
<span class="auto-style2">    image :         OpenCV 形式の画像</span>
<span class="auto-style2">[Return]</span>
<span class="auto-style2">    認識結果</span>
<span class="auto-style2">'''</span>
<span class="auto-style2">def DetectFaces(cascade, image):</span>
<span class="auto-style2">    # 顔検出のためにグレイスケール画像に変換</span>
<span class="auto-style2">    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span>

<span class="auto-style2">    # 顔を画像から検出 </span>
<span class="auto-style2">    face_list = cascade.detectMultiScale(img_gray, minSize=(100, 100))</span>

<span class="auto-style2">    # 検出結果を返す</span>
<span class="auto-style2">    return face_list</span>


<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    検出された顔枠情報リストを使って、image 上に赤枠を描画する。</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    image :         OpenCV 形式の画像</span>
<span class="auto-style2">    face_list :     検出された顔枠情報リスト</span>
<span class="auto-style2">[Return]</span>
<span class="auto-style2">    無し</span>
<span class="auto-style2">'''</span>
<span class="auto-style2">def DrawFaceRectangles(image, face_list):</span>
<span class="auto-style2">    # 検出した顔の数だけ赤枠を描画</span>
<span class="auto-style2">    if len(face_list) != 0:</span>
<span class="auto-style2">        for (pos_x, pos_y, w, h) in face_list:</span>
<span class="auto-style2">            print(f"pos_x = {pos_x}, pos_y = {pos_y}, w = {w}, h = {h}")</span>
<span class="auto-style2">            cv2.rectangle(image, (pos_x, pos_y), (pos_x + w, pos_y + h), (0,0,255), thickness=5)</span>


'''
[Abstract]
    main 関数
'''
if __name__ == '__main__':

    cap = cv2.VideoCapture(url) 

    #
    windowInitialized = False

<span class="auto-style2">    # 顔を識別するためのファイル</span>
<span class="auto-style2">    cascade_file = "haarcascade_frontalface_alt2.xml"       # 顔</span>
<span class="auto-style2">    #cascade_file = "haarcascade_eye.xml"                   # 目？</span>
<span class="auto-style2">    #cascade_file = "haarcascade_eye_tree_eyeglasses.xml"   # 目？</span>
<span class="auto-style2">    cascade = cv2.CascadeClassifier(cascade_file)</span>

    while True:
        try:
            ret, frame = cap.read()
            if ret == True:
<span class="auto-style2">                # 顔検知</span>
<span class="auto-style2">                face_list = DetectFaces(cascade, frame)</span>

<span class="auto-style2">                # 検出した顔枠を描画</span>
<span class="auto-style2">                DrawFaceRectangles(frame, face_list)</span>

                # PC画面サイズに合わせて適当にリサイズ後、表示
                frame2 = cv2.resize(frame, (1280, 720))
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # 最初の起動時のみ表示位置を指定
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True

            # Press the "q" key to finish.
            k = cv2.waitKey(1) &amp; 0xff   # necessary to display the video by imshow ()
            if k == ord("q"):
                break
            
            # 指定ウィンドウが無かったら終了
            if not IsWindowVisible(winname):
                break


        except KeyboardInterrupt:
            print("KeyboardInterrupt")
            break

    cap.release()
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>結果：</p>
  <p>私のゲーミングPCではこれでもそこそこ動作しました。思ったより動く、という感想です。</p>
  <p>が、それでもだんだん映像が遅れていきます。<br>顔検知処理と描画の部分をコメントアウトすると、映像表示の遅れはなくなります。<br>
  やはり顔検知処理は PC にとって結構重たい処理のようです。</p>
  <p>ちょっと残念。何か改善策を考えてみたいところです。</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <h3><a name="4-2._顔検知部分を別プロセスの処理にしてみる">4-2. 顔検知部分を別プロセスの処理にしてみる</a></h3>
  <p>
  そこで、顔検知部分を別タスクに分離することで、映像受信と映像デコード処理を止めずにできるだけ顔検知をやってみる、という感じにプログラムを修正してみます。</p>
  <p>別タスクというと一般的なプログラムでは "スレッド" というテクニックを使いますが、どうやら CPython 
  と呼ばれるプラットフォームの場合はスレッドは複数の処理を同時に実行してくれないらしいです。そこで、ここでは別プロセスを起動し、キューと呼ばれるIOで情報をやり取りしてみます。</p>
  <p>&nbsp;</p>
  <p>[プログラムソース &quot;<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_3_2.py" target="_blank">connect_with_mjpeg_3_2.py</a>&quot;]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    i-PRO mini (WV-S7130W) と接続して映像を表示してみる。
    ここでは opencv を使って顔検知を追加してみます。

[Library install]
    pip install opencv-python

[OpenCV]
    下記URLからファイル "haarcascade_frontalface_alt2.xml" を入手すること
    https://github.com/opencv/opencv/tree/master/data/haarcascades 
'''

import cv2
<span class="auto-style2">import multiprocessing as mp</span>
<span class="auto-style2">from queue import Empty</span>


user_id     = "user-id"         # ご使用のカメラ設定に合わせて変更
user_pw     = "password"        # ご使用のカメラ設定に合わせて変更
host        = "192.168.0.10"    # ご使用のカメラ設定に合わせて変更
winname     = "VIDEO"           # ウィンドウタイトル
resolution  = "1920x1080"       # 解像度
framerate   =  30               # フレームレート

# URL
url = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"

<span class="auto-style2"># 顔を識別するためのファイル</span>
<span class="auto-style2">cascade_file = "haarcascade_frontalface_alt2.xml"       # 顔</span>
<span class="auto-style2">#cascade_file = "haarcascade_eye.xml"                   # 目？</span>
<span class="auto-style2">#cascade_file = "haarcascade_eye_tree_eyeglasses.xml"   # 目？</span>
<span class="auto-style2">cascade = cv2.CascadeClassifier(cascade_file)</span>


# Exception 定義
BackendError = type('BackendError', (Exception,), {})

'''
[Abstract]
    対象ウィンドウが存在するかを確認する。
[Param]
    winname :       ウィンドウタイトル
[Return]
    True :          対象ウィンドウは存在する
    False :         対象ウィンドウは存在しない
[Exception]
    BackendError :  バックエンドで使用している Qt でエラー発生
'''
def IsWindowVisible(winname):
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False


'''
[Abstract]
    顔検知して認識結果を返す
[Param]
    cascade :       OpenCV の CascadeClassifierオブジェクト
    image :         OpenCV 形式の画像
[Return]
    検出結果
'''
def DetectFaces(cascade, image):
    # 顔検出のためにグレイスケール画像に変換
    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # 検出した顔の位置情報を取得
    face_list = cascade.detectMultiScale(img_gray, minSize=(100, 100))

    return face_list


<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    顔検知タスク</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    q1 :        [i] 顔検知する画像を保存する Queue</span>
<span class="auto-style2">    q2 :        [o] 顔検知した結果を保存する Queue</span>
<span class="auto-style2">[Return]</span>
<span class="auto-style2">    無し</span>
<span class="auto-style2">'''</span>
<span class="auto-style2"># def DetectFacesProcess(cascade, q1, q2):</span>
<span class="auto-style2">def DetectFacesProcess(q1, q2):</span>
<span class="auto-style2">    while True:</span>
<span class="auto-style2">        try:</span>
<span class="auto-style2">            image = q1.get(True, 10)</span>

<span class="auto-style2">            # 終了処理： q1.get から取得したものが int で -1 なら終了</span>
<span class="auto-style2">            if type(image) == int:</span>
<span class="auto-style2">                if image == -1:</span>
<span class="auto-style2">                    break</span>

<span class="auto-style2">            # 顔検知</span>
<span class="auto-style2">            face_list = DetectFaces(cascade, image)</span>

<span class="auto-style2">            q2.put(face_list)</span>
<span class="auto-style2">        except Empty: # timeout of q1.get()</span>
<span class="auto-style2">            print("Timeout happen.")</span>

<span class="auto-style2">    print("Finish DetectFacesProcess()")    </span>


'''
[Abstract]
    検出された顔枠情報リストを使って、image 上に赤枠を描画する。
[Param]
    image :         OpenCV 形式の画像
    face_list :     検出された顔枠情報リスト
[Return]
    無し
'''
def DrawFaceRectangles(image, face_list):
    # 検出した顔の数だけ赤枠を描画
    if len(face_list) != 0:
        for (pos_x, pos_y, w, h) in face_list:
            print(f"pos_x = {pos_x}, pos_y = {pos_y}, w = {w}, h = {h}")
            cv2.rectangle(frame, (pos_x, pos_y), (pos_x + w, pos_y + h), (0,0,255), thickness=5)


'''
[Abstract]
    main 関数 
'''
if __name__ == '__main__':

    cap = cv2.VideoCapture(url) 

    #
    windowInitialized = False

<span class="auto-style2">    q1 = mp.Queue()</span>
<span class="auto-style2">    q2 = mp.Queue()</span>

<span class="auto-style2">    # "cannot pickle object" というエラーが出て解決できなかったので、args に cascade を加えるのを断念</span>
<span class="auto-style2">    # 合わせて cascade をグローバル変数に。</span>
<span class="auto-style2">    p = mp.Process(target=DetectFacesProcess, args=(q1, q2))</span>
<span class="auto-style2">    # p = mp.Process(target=DetectFacesProcess, args=(cascade, q1, q2))</span>
<span class="auto-style2">    p.start()</span>

    init = False

    while True:
        try:
            ret, frame = cap.read()
            if ret == True:
<span class="auto-style2">                # 顔検知</span>
<span class="auto-style2">                if (q1.qsize() &lt;= 1) and (q2.qsize() &lt;= 1):</span>
<span class="auto-style2">                    q1.put(frame)</span>

<span class="auto-style2">                if q2.qsize() != 0:</span>
<span class="auto-style2">                    face_list = q2.get()</span>
<span class="auto-style2">                    init = True</span>

<span class="auto-style2">                if init == True:</span>
<span class="auto-style2">                    # 検出した顔枠を描画</span>
<span class="auto-style2">                    DrawFaceRectangles(frame, face_list)</span>

                # PC画面サイズに合わせて適当にリサイズ後、表示
                frame2 = cv2.resize(frame, (1280, 720))
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # 最初の起動時のみ表示位置を指定
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True

            # Press the "q" key to finish.
            k = cv2.waitKey(1) &amp; 0xff   # necessary to display the video by imshow ()
            if k == ord("q"):
                break
            
            # 指定ウィンドウが無かったら終了
            if not IsWindowVisible(winname):
                break


        except KeyboardInterrupt:
            print("KeyboardInterrupt")
            break

<span class="auto-style2">    # Terminate process p</span>
<span class="auto-style2">    q1.put(-1)</span>
<span class="auto-style2">    # Waiting for process p to finish</span>
<span class="auto-style2">    p.join()</span>

    print("Finish main()")
    cap.release()
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>結果：</p>
  <p>期待する動作をしてくれるようになりました。</p>
  <p>プロセス起動の引数として cascade を一緒に渡したかったのですが、"cannot pickle object" 
  というエラーを発生して実現できませんでした。残念ながら cascade をグローバル変数へ変更することで問題を回避しています。<br>対応策がわかったら記事をアップデートしたいと思います。</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  
	<video controls muted autoplay="y" loop="y" src="connect_with_mjpeg/mjpeg_opencv_30fps.mp4" width="800px">
	  <p>動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。</p>
  </video>

  <p>[動画] OpenCV で顔検知してみた様子 (30fps) （注意：ストリーム1～4 を全て Off に設定しています）</p>
  
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  
</section>

<section>
  <h2><a name="5._連番の_JPEG_ファイルで保存する">5. 連番の JPEG ファイルで保存する</a></h2>
  <p>受信した画像を 1 から始まる連番のファイル名 (image_NNNNNN.jpg) で JPEG ファイルとして保存してみます。</p>
  <p>&nbsp;</p>
  <ul>
    <li>JPEG 情報はカメラから受信したデータをそのままに保存するようにします。</li>
    <li>"image" という名称でフォルダを作成し、ここに "image_000001.jpg" というようなファイル名で画像を保存します。</li>
  </ul>

	<p>&nbsp;</p>

	<h4>[評価環境]</h4>
	<table>
	<tbody>
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>言語 :</td>
	    <td>Python,</td>
	    <td>3.10.4 </td>
	  </tr>
		
	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
		
	  <tr>
	    <td>OS :</td>
	    <td>Windows 11 home,</td>
	    <td>21H2</td>
	  </tr>
	  <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>

	  <tr>
	    <td class="td_separate" colspan="3"></td>
	  </tr>
	</tbody>
	</table>
	
  <p>&nbsp;</p>
  <p>[プログラムソース "<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_4.py" target="_blank">connect_with_mjpeg_4.py</a>"]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    MJPEG(Motion JPEG) で i-PRO カメラと接続します

[Details]
    受信した JPEG 画像をファイル保存します。
    ファイル名の末尾に６ケタの番号を付けて連番で保存します。

[Library install]
    pip install opencv-python
'''
import cv2
import numpy as np
import os
import urllib.request as rq

user_id     = "user-id"         # ご使用のカメラ設定に合わせて変更
user_pw     = "password"        # ご使用のカメラ設定に合わせて変更
host        = "192.168.0.10"    # ご使用のカメラ設定に合わせて変更
winname     = "VIDEO"           # ウィンドウタイトル
resolution  = "1920x1080"       # 解像度
framerate   =  5                # フレームレート
pathOut     = 'image'           # 画像ファイル保存フォルダ

# URL
url = f"http://{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"

# Exception 定義
BackendError = type('BackendError', (Exception,), {})

'''
[Abstract]
    対象ウィンドウが存在するかを確認する。
[Param]
    winname :       ウィンドウタイトル
[Return]
    True :          対象ウィンドウは存在する
    False :         対象ウィンドウは存在しない
[Exception]
    BackendError :  バックエンドで使用している Qt でエラー発生
'''
def IsWindowVisible(winname):
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False


'''
[abstract]
    IP カメラと認証処理を行います。

[params]
    uri:      mjpeg 開始 CGI コマンド
    user:     IPカメラの user-id
    passwd:   IPカメラの user-password
'''
def set_digest_auth(uri, user, passwd):
    pass_mgr = rq.HTTPPasswordMgrWithDefaultRealm()
    pass_mgr.add_password(realm=None, uri=uri, user=user, passwd=passwd)
    auth_handler = rq.HTTPDigestAuthHandler(pass_mgr)
    opener = rq.build_opener(auth_handler)
    rq.install_opener(opener)


<span class="auto-style2">'''</span>
<span class="auto-style2">[Abstract]</span>
<span class="auto-style2">    バイナリデータを指定ファイル名で保存する</span>
<span class="auto-style2">[Param]</span>
<span class="auto-style2">    data :      保存するバイナリデータ</span>
<span class="auto-style2">    filename :  ファイル名</span>
<span class="auto-style2">'''</span>
<span class="auto-style2">def SaveBinaryData(data, filename):</span>
<span class="auto-style2">    fout = open(filename, 'wb')</span>
<span class="auto-style2">    fout.write(data)</span>
<span class="auto-style2">    fout.close()</span>


'''
[Abstract]
    main 関数
'''
if __name__ == '__main__':

    windowInitialized = False
<span class="auto-style2">    count = 0</span>
<span class="auto-style2">    if not os.path.exists(pathOut):</span>
<span class="auto-style2">        os.mkdir(pathOut)</span>

    set_digest_auth(url, user_id, user_pw)
    stream = rq.urlopen(url)

    bytes = bytes()
    while True:
        bytes += stream.read(1024)
        a = bytes.find(b'\xff\xd8')     # SOI スタートマーカ (Start of Image)  0xFFD8
        b = bytes.find(b'\xff\xd9')     # EOI エンドマーカ   (End   of Image)  0xFFD9
        if a != -1 and b != -1:
            jpg = bytes[a:b+2]
            bytes = bytes[b+2:]

<span class="auto-style2">            # ファイル保存</span>
<span class="auto-style2">            count += 1</span>
<span class="auto-style2">            filename = os.path.join(pathOut, 'image_{:06d}.jpg'.format(count))</span>
<span class="auto-style2">            SaveBinaryData(jpg, filename)</span>

            # binary データを ndarray 型へ変換
            img_buf = np.frombuffer(jpg, dtype=np.uint8)

            # バイナリデータをデコードして画像データ(OpenCV形式)にする
            frame = cv2.imdecode(img_buf, cv2.IMREAD_UNCHANGED)

            # リサイズ
            frame2 = cv2.resize(frame, (1280, 720))

            # 映像表示
            cv2.imshow(winname, frame2)

            if windowInitialized==False:
                # 最初の起動時のみ表示位置を指定
                cv2.moveWindow(winname, 100, 100)
                windowInitialized = True

            # "z" キーを押されていたら終了
            if cv2.waitKey(1) &amp; 0xFF == ord('z'):
                break

            # 指定ウィンドウが無かったら終了
            if not IsWindowVisible(winname):
                break

    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>

<p>&nbsp;</p>

<section>
  <h2><a name="6._映像切断時の再接続処理を追加">6. 映像切断時の再接続処理を追加</a></h2>
  <p>ここまでのプログラムは、カメラとの接続が30秒以上切断すると接続が復活しませんでした。<br>OpenCV の read() 
  関数のタイムアウトは30秒となっているようです。30秒以内に接続が復活していれば自動的に再接続してくれるのですが、30秒を超えると自動的には復活しません。</p>
  <p>"connect_with_rtsp_2.py" を元に再接続処理を追加してこの問題を解決してみたいと思います。</p>
  <p>&nbsp;</p>
  <p><strong>ポイント</strong></p>
  <ul>
    <li>read() の戻り値が False であったら再接続を行います。</li>
    <li>release() で切断後、cv2.VideoCapture() で再接続します。</li>
  </ul>
  <p>&nbsp;</p>
  <p><strong>NOTE</strong></p>
  <ul>
    <li>切断の試験はカメラの電源をOff/Onする、通信をOff/Onする、などで試験してください。</li>
    <li>カメラとの接続が正常状態に戻ってから再接続までは最長30秒かかります。気長にお待ちください。</li>
    <li>read() のタイムアウト時間を変更する API を確認できませんでした。おそらく固定値で変更できないと思われます。</li>
  </ul>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <h4>[評価環境]</h4>
  <table>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>言語 :</td>
      <td>Python,</td>
      <td>3.10.4 </td>
    </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>OS :</td>
      <td>Windows 11 home,</td>
      <td>21H2</td>
    </tr>
    <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
  </table>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>[プログラムソース "<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_5.py" target="_blank">connect_with_mjpeg_5.py</a>"]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with RTSP.
    RTSP で i-PRO カメラと接続してみる。

[Details]
    Add reconnection when video is disconnected to "connect_with_mjpeg_2.py".
    映像切断時の再接続処理を"connect_with_mjpeg_2.py"へ追加する。

[Library install]
    pip install opencv-python
'''

from nturl2path import url2pathname
import cv2

user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
resolution  = "1920x1080"       # Resolution
framerate   =  15               # Frame rate
url         = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"

#
windowInitialized = False

# Exception definition.
BackendError = type('BackendError', (Exception,), {})

'''
[Abstract]
    Check if the target window exists.
    対象ウィンドウが存在するかを確認する。
[Param]
    winname :       Window title
[Return]
    True :          exist
                    存在する
    False :         not exist
                    存在しない
[Exception]
    BackendError :
'''
def IsWindowVisible(winname):
    try:
        ret = cv2.getWindowProperty(winname, cv2.WND_PROP_VISIBLE)
        if ret == -1:
            raise BackendError('Use Qt as backend to check whether window is visible or not.')

        return bool(ret)

    except cv2.error:
        return False


'''
[Abstract]
    main function.
'''
if __name__ == '__main__':

    cap = cv2.VideoCapture(url)

    while True:
        try:
            ret, frame = cap.read()
            if ret == True:
                # Please modify the value to fit your PC screen size.
                frame2 = cv2.resize(frame, (1280, 720))
                # Display video.
                cv2.imshow(winname, frame2)

                if windowInitialized==False:
                    # Specify window position only once at startup.
                    cv2.moveWindow(winname, 100, 100)
                    windowInitialized = True
<span class="auto-style2">            else:</span>
<span class="auto-style2">                print("cap.read() return False.")</span>
<span class="auto-style2">                # The timeout period seems to be 30 seconds.</span>
<span class="auto-style2">                # And there seems to be no API to change the timeout value.</span>

<span class="auto-style2">                # Reconnect</span>
<span class="auto-style2">                cap.release()</span>
<span class="auto-style2">                cap = cv2.VideoCapture(url)</span>

            # Press the "z" key to finish.
            k = cv2.waitKey(1)
            if k == ord("z"):
                break
            
            # Exit the program if there is no specified window.
            if not IsWindowVisible(winname):
                break
        
        except KeyboardInterrupt:
            # Press'[ctrl] + [c]' on the console to exit the program.
            print("KeyboardInterrupt")
            break

    cap.release()
    cv2.destroyAllWindows()</pre>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>

<p>&nbsp;</p>

<section>
  <h2><a name="7._GUIで映像表示してみる（tkinter）">7. GUIで映像表示してみる（tkinter）</a></h2>
  <p>ここまでのプログラムは全てOpenCVが作成するウィンドウ表示でした。<br>ここでは独自の GUI を作成してここに映像表示する例を示します。</p>
  <p>GUI 表示の実現方法もいろいろありますが、ここでは Python 標準の tkinter を使用してみます。</p>
  <p>&nbsp;</p>
  <p>tkinter のインストール方法は環境により異なるようです。各人の環境にあった方法をインターネットで調べて実施してください。</p>
  <p>&nbsp;</p>
  <p><strong>ポイント</strong></p>
  <ul>
    <li>tkinter で動画を表示するときは、after() 関数で繰り返し処理を行います。</li>
    <li>tkinter で表示するために ImageTk.PhotoImage という型に変換する必要があります。<br>numpy.ndarray → 
    PIL.Image → ImageTk.PhotoImage という順に変換して tkinter で表示します。</li>
    <li>OpenCVの画像は BGR の並び順になっています。tkinker で表示するために BGR データを RGB へ並び替える必要があります。</li>
  </ul>
  <p>&nbsp;</p>
  <p>「<a href="connect_with_rtsp.html#7-3. メニュー・ボタンを追加して GUI アプリらしくしてみる">RTSP で画像を取得する ： 7-3. メニュー・ボタンを追加して GUI 
  アプリらしくしてみる</a>」で既に 
  GUI 版を作成済みなので、プログラム "connect_with_rtsp_6_3.py" 
  をベースに変更箇所のみをわかるように以下で記載します。ほとんど同じ内容で実現できます。</p>
  <p>&nbsp;</p>
  <h4>[評価環境]</h4>
  <table>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>言語 :</td>
      <td>Python,</td>
      <td>3.10.4 </td>
    </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>Tcl/Tk,</td>
      <td>8.6 </td>
    </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
    <tr>
      <td>OS :</td>
      <td>Windows 11 home,</td>
      <td>21H2</td>
    </tr>
    <tr>
	    <td></td>
	    <td>Windows 10 Pro,</td>
	    <td>21H1</td>
	  </tr>
    <tr>
      <td class="td_separate" colspan="3"></td>
    </tr>
  </table>
  <p>&nbsp;</p>
  <p>[プログラムソース "<a href="https://github.com/i-pro-corp/python-examples/blob/main/connect_with_mjpeg/connect_with_mjpeg_6.py" target="_blank">connect_with_mjpeg_6.py</a>"]</p>
  <pre class="prettyprint linenums lang-py">'''
[Abstract]
    Try connecting to an i-PRO camera with MJPEG.
    MJPEG で i-PRO カメラと接続してみる。

[Details]
    Display the video with GUI using tkinter.
    Add menus and buttons to make it look like a GUI app.
    
    tkinter を使ったGUIで映像を表示します。
    メニューとボタンを追加してGUIアプリらしくします。

    BGR → RGB
    numpy.ndarray → PIL.Image → ImageTk.PhotoImage
    (1) BGR → RGB
    (2) numpy.ndarray → PIL.Image
    (3) PIL.Image → ImageTk.PhotoImage

[Library install]
    pip install opencv-python
'''

import cv2
import time
import tkinter as tk
from tkinter import messagebox
from PIL import Image, ImageTk, ImageOps
import multiprocessing as mp


user_id     = "user-id"         # Change to match your camera setting
user_pw     = "password"        # Change to match your camera setting
host        = "192.168.0.10"    # Change to match your camera setting
winname     = "VIDEO"           # Window title
<span class="auto-style2">resolution  = "1920x1080"       # Resolution</span>
<span class="auto-style2">framerate   =  15               # Frame rate</span>
<span class="auto-style2">url         = f"http://{user_id}:{user_pw}@{host}/cgi-bin/nphMotionJpeg?Resolution={resolution}&amp;Quality=Standard&amp;Framerate={framerate}"</span>


class Application(tk.Frame):
    def __init__(self, master = None):
        super().__init__(master)
        self.pack()

        # Window settings.
        self.master.title("Display i-PRO camera with tkinter")      # Window title
        self.master.geometry("800x600+100+100")                     # Window size, position

        # Event registration for window termination.
        self.master.protocol("WM_DELETE_WINDOW", self.on_closing_window)

        # Create menu.
        menubar = tk.Menu(self.master)
        self.master.configure(menu=menubar)
        filemenu = tk.Menu(menubar)
        menubar.add_cascade(label='File', menu=filemenu)
        filemenu.add_command(label='Quit', command = self.on_closing_window)

        # Create button_frame
        self.button_frame = tk.Frame(self.master, padx=10, pady=10, relief=tk.RAISED, bd=2)
        self.button_frame.pack(side = tk.BOTTOM, fill=tk.X)

        # Create quit_button
        self.quit_button = tk.Button(self.button_frame, text='Quit', width=10, command = self.on_closing_window)
        self.quit_button.pack(side=tk.RIGHT)
        
        # Create canvas.
        self.canvas = tk.Canvas(self.master)

        # Add mouse click event to canvas.
        self.canvas.bind('&lt;Button-1&gt;', self.canvas_click)

        # Place canvas.
        self.canvas.pack(expand = True, fill = tk.BOTH)

        # Create image receiving process and queue
        self.imageQueue = mp.Queue()
        self.request = mp.Value('i', 0)     # -1 : Exit ReceiveImageProcess.
                                            #  0 : Normal.
                                            #  1 : Connect camera.
                                            #  2 : Release camera.
        self.p = mp.Process(target=ReceiveImageProcess, args=(self.imageQueue, self.request))
        self.p.start()

        # Raise a video display event (disp_image) after 500m
        self.disp_id = self.after(500, self.disp_image)

    def on_closing_window(self):
        ''' Window closing event. '''

        if messagebox.askokcancel("QUIT", "Do you want to quit?"):
            # Request terminate process self.p.
            self.request.value = -1

            # Waiting for process p to finish
            time.sleep(1)

            # Flash buffer.
            # The program cannot complete p.join() unless the imageQueue is emptied.
            for i in range(self.imageQueue.qsize()):
                pil_image = self.imageQueue.get()

            # Wait for process p to be terminated.
            self.p.join()
            self.master.destroy()
            print("Finish Application.")

    def canvas_click(self, event):
        ''' Event handling with mouse clicks on canvas '''

        if self.disp_id is None:
            # Connect camera.
            self.request.value = 1
            # Display image.
            self.disp_image()

        else:
            # Release camera.
            self.request.value = 2
            # Cancel scheduling
            self.after_cancel(self.disp_id)
            self.disp_id = None

    def disp_image(self):
        ''' Display image on Canvas '''

        # If there is data in the imageQueue, the program receives the data and displays the video.
        num = self.imageQueue.qsize()
        if num &gt; 0:
            if (num &gt; 5):
                num -= 1
            for i in range(num):
                cv_image = self.imageQueue.get()

            # (2) Convert image from ndarray to PIL.Image.
            pil_image = Image.fromarray(cv_image)

            # Get canvas size.
            canvas_width = self.canvas.winfo_width()
            canvas_height = self.canvas.winfo_height()

            # Resize the image to the size of the canvas without changing the aspect ratio.
            # アスペクトを維持したまま画像を Canvas と同じサイズにリサイズ
            pil_image = ImageOps.pad(pil_image, (canvas_width, canvas_height))

            # (3) Convert image from PIL.Image to PhotoImage
            # PIL.Image から PhotoImage へ変換する
            self.photo_image = ImageTk.PhotoImage(image=pil_image)

            # Display image on the canvas.
            self.canvas.create_image(
                canvas_width / 2,       # Image display position (center of the canvas)
                canvas_height / 2,                   
                image=self.photo_image  # image data
                )
            
        else:
            pass

        # Raise a video display event (disp_image) after 1ms.
        self.disp_id = self.after(1, self.disp_image)


def ReceiveImageProcess(imageQueue, request):
    '''
    Receive Image Process.

    Args:
        imageQueue      [o] This process stores the received image data in the imageQueue.
        request         [i] Shared memory for receiving requests from the main process.
                            -1: Terminate process.
                             0: Nothing.
                             1: Connect camera.
                             2: Release camera connection.
    Returns:
        None
    Raises
        None
    '''

    # Connect camera.
    cap = cv2.VideoCapture(url)

    while True:
        if cap != None:
            # Get frame.
            ret, frame = cap.read()

            if ret == True:
                # (1) Convert image from BGR to RGB.
                cv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                if imageQueue.qsize() &lt; 10:
                    imageQueue.put(cv_image)

            else:
                print("cap.read() return False.")
                # The timeout period seems to be 30 seconds.
                # And there seems to be no API to change the timeout value.
                time.sleep(1)

                # Reconnect
                cap.release()
                cap = cv2.VideoCapture(url)
        else:
            time.sleep(0.1)
                
        # Check process termination request.
        if request.value == -1:
            # Terminate process.
            cap.release()
            request.value = 0
            break

        # Check connect request.
        if request.value == 1:
            cap = cv2.VideoCapture(url)
            request.value = 0

        # Check release request.
        if request.value == 2:
            cap.release()
            cap = None
            request.value = 0

    print("Terminate SaveImageProcess().")


if __name__ == "__main__":
    root = tk.Tk()
    app = Application(master = root)
    app.mainloop()</pre>
  <p>&nbsp;</p>
  <p>
    <video controls muted autoplay="y" loop="y" width="800px">
      <source src="connect_with_mjpeg/mjpeg_6.mp4" type="video/mp4">
      動画を再生するには &lt;video&gt; タグをサポートしたブラウザが必要です。
    </video>
  </p>
  <p>[動画] tkinter で作成した GUI アプリ</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>

<p>&nbsp;</p>

<section>
  <h2><a name="ソースコード所在">ソースコード所在</a></h2>
  <p>本ページで紹介のソースコードは、下記 github より取得できます。</p>
  <p>下記 github のソースコードと本ページの内容は差異がある場合があります。</p>
  <p><a href="https://github.com/i-pro-corp/python-examples" target="_blank">i-pro-corp/python-examples: Examples for i-PRO cameras. (github.com)</a></p>
  <p>&nbsp;</p>
</section>

<p>

<br>

</p>

<section>
  <h2><a name="ライセンス">ライセンス</a></h2>
<p>本ページの情報は、特記無い限り下記ライセンスで提供されます。</p>
<table class="border-collapse" style="width: 600px; background-color: #F0F0F0; word-break: break-word;">
  <tr>
    <td>
    <br>Copyright 2022 i-PRO Co., Ltd.<br><br>Licensed under the Apache License, Version 
    2.0 (the "License");<br>you may not use this file except in compliance with 
    the License.<br>You may obtain a copy of the License at <br><br>&nbsp;&nbsp;&nbsp;
    <a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank">http://www.apache.org/licenses/LICENSE-2.0</a><br><br>
    Unless required by 
    applicable law or agreed to in writing, software <br>distributed under the 
    License is distributed on an "AS IS" BASIS, <br>WITHOUT WARRANTIES OR 
    CONDITIONS OF ANY KIND, either express or implied. <br>See the License for 
    the specific language governing permissions and<br>limitations under the 
    License. <br> <br>
    </td>
  </tr>
</table>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</section>


<section>
	<h2><a name="参考">参考</a></h2>
	<ul>
		<li>[1] ネットワークカメラCGIコマンドインターフェース仕様書　統合版<br>
      <a href="https://sol.panasonic.biz/security/cgi-bin/ipro/download/tbookmarka_m.cgi?m=%20&amp;mm=2012100910461872" target="_blank">https://sol.panasonic.biz/security/cgi-bin/ipro/download/tbookmarka_m.cgi?m=%20&amp;mm=2012100910461872</a></li>
    <li>[2] python - How to parse mjpeg http stream from ip camera? - Stack Overflow<br>
      <a href="https://stackoverflow.com/questions/21702477/how-to-parse-mjpeg-http-stream-from-ip-camera" target="_blank">https://stackoverflow.com/questions/21702477/how-to-parse-mjpeg-http-stream-from-ip-camera</a></li>
	</ul>
</section>

<p>&nbsp;</p>

<hr>

<p>&nbsp;</p>

<section>
	<h2 style="margin-bottom:5px">変更履歴</h2>
	<table>
	  <tr>
	    <td class="td_history_date">2022/5/26</td>
	    <td class="td_history_separator">-</td>
	    <td class="td_history">新規作成,</td>
	    <td class="td_history">木下英俊 </td>
	  </tr>
	</table>
</section>

<p>&nbsp;</p>
<p><a href="../../index.html" target="_parent">i-PRO - Programming Items トップページ</a></p>
<p><a href="../../privacy_policy.html">プライバシーポリシー</a></p>
<p>&nbsp;</p>

<footer>
	<p><small>&copy; 2022  i-PRO Co., Ltd.</small></p>
</footer>

</body>
</html>
